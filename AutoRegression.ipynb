{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c946e0a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:10.203834Z",
     "iopub.status.busy": "2025-11-22T15:32:10.203146Z",
     "iopub.status.idle": "2025-11-22T15:32:17.901724Z",
     "shell.execute_reply": "2025-11-22T15:32:17.900800Z"
    },
    "papermill": {
     "duration": 7.706184,
     "end_time": "2025-11-22T15:32:17.903003",
     "exception": false,
     "start_time": "2025-11-22T15:32:10.196819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Step 0: Imports & Config\n",
    "# ======================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665441e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:17.913596Z",
     "iopub.status.busy": "2025-11-22T15:32:17.912817Z",
     "iopub.status.idle": "2025-11-22T15:32:22.153345Z",
     "shell.execute_reply": "2025-11-22T15:32:22.152300Z"
    },
    "papermill": {
     "duration": 4.247334,
     "end_time": "2025-11-22T15:32:22.154834",
     "exception": false,
     "start_time": "2025-11-22T15:32:17.907500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading week 01 ...\n",
      "Loading week 02 ...\n",
      "Loading week 03 ...\n",
      "Loading week 04 ...\n",
      "\n",
      "==== Step 1: 原始多周数据形状 ====\n",
      "input_df shape : (1144532, 24)\n",
      "output_df shape: (130495, 7)\n",
      "weeks in input_df : [1, 2, 3, 4]\n",
      "weeks in output_df: [1, 2, 3, 4]\n",
      "\n",
      "input_df columns: ['game_id', 'play_id', 'player_to_predict', 'nfl_id', 'frame_id', 'play_direction', 'absolute_yardline_number', 'player_name', 'player_height', 'player_weight', 'player_birth_date', 'player_position', 'player_side', 'player_role', 'x', 'y', 's', 'a', 'dir', 'o', 'num_frames_output', 'ball_land_x', 'ball_land_y', 'week']\n",
      "output_df columns: ['game_id', 'play_id', 'nfl_id', 'frame_id', 'x', 'y', 'week']\n",
      "\n",
      "input_df 示例行：\n",
      "      game_id  play_id  player_to_predict  nfl_id  frame_id play_direction  absolute_yardline_number player_name player_height  player_weight player_birth_date player_position player_side  \\\n",
      "0  2023090700      101              False   54527         1          right                        42  Bryan Cook           6-1            210        1999-09-07              FS     Defense   \n",
      "1  2023090700      101              False   54527         2          right                        42  Bryan Cook           6-1            210        1999-09-07              FS     Defense   \n",
      "2  2023090700      101              False   54527         3          right                        42  Bryan Cook           6-1            210        1999-09-07              FS     Defense   \n",
      "\n",
      "          player_role      x      y     s     a     dir       o  num_frames_output  ball_land_x  ball_land_y  week  \n",
      "0  Defensive Coverage  52.33  36.94  0.09  0.39  322.40  238.24                 21    63.259998        -0.22     1  \n",
      "1  Defensive Coverage  52.33  36.94  0.04  0.61  200.89  236.05                 21    63.259998        -0.22     1  \n",
      "2  Defensive Coverage  52.33  36.93  0.12  0.73  147.55  240.60                 21    63.259998        -0.22     1  \n",
      "\n",
      "output_df 示例行：\n",
      "      game_id  play_id  nfl_id  frame_id      x      y  week\n",
      "0  2023090700      101   46137         1  56.22  17.28     1\n",
      "1  2023090700      101   46137         2  56.63  16.88     1\n",
      "2  2023090700      101   46137         3  57.06  16.46     1\n",
      "\n",
      "play_direction 计数：\n",
      "play_direction\n",
      "right    601684\n",
      "left     542848\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Step 1: Load input/output data\n",
    "# ======================================\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 先用 1~4 周，跑顺了再扩展\n",
    "weeks = [f\"{w:02d}\" for w in range(1, 5)]   # [\"01\",\"02\",\"03\",\"04\"]\n",
    "\n",
    "input_list = []\n",
    "output_list = []\n",
    "\n",
    "for w in weeks:\n",
    "    in_path  = f\"/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w{w}.csv\"\n",
    "    out_path = f\"/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w{w}.csv\"\n",
    "    \n",
    "    print(f\"Loading week {w} ...\")\n",
    "    input_w  = pd.read_csv(in_path)\n",
    "    output_w = pd.read_csv(out_path)\n",
    "\n",
    "    # 可选：加 week 标记，方便以后分析\n",
    "    input_w[\"week\"]  = int(w)\n",
    "    output_w[\"week\"] = int(w)\n",
    "    \n",
    "    input_list.append(input_w)\n",
    "    output_list.append(output_w)\n",
    "\n",
    "input_df  = pd.concat(input_list,  ignore_index=True)\n",
    "output_df = pd.concat(output_list, ignore_index=True)\n",
    "\n",
    "print(\"\\n==== Step 1: 原始多周数据形状 ====\")\n",
    "print(\"input_df shape :\", input_df.shape)\n",
    "print(\"output_df shape:\", output_df.shape)\n",
    "print(\"weeks in input_df :\", sorted(input_df['week'].unique().tolist()))\n",
    "print(\"weeks in output_df:\", sorted(output_df['week'].unique().tolist()))\n",
    "\n",
    "print(\"\\ninput_df columns:\", list(input_df.columns))\n",
    "print(\"output_df columns:\", list(output_df.columns))\n",
    "\n",
    "print(\"\\ninput_df 示例行：\")\n",
    "print(input_df.head(3))\n",
    "\n",
    "print(\"\\noutput_df 示例行：\")\n",
    "print(output_df.head(3))\n",
    "\n",
    "print(\"\\nplay_direction 计数：\")\n",
    "print(input_df[\"play_direction\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37641e5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:22.165253Z",
     "iopub.status.busy": "2025-11-22T15:32:22.165006Z",
     "iopub.status.idle": "2025-11-22T15:32:22.380654Z",
     "shell.execute_reply": "2025-11-22T15:32:22.379772Z"
    },
    "papermill": {
     "duration": 0.222542,
     "end_time": "2025-11-22T15:32:22.382117",
     "exception": false,
     "start_time": "2025-11-22T15:32:22.159575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Step 2: 过滤 player_to_predict 后 ====\n",
      "input_df shape (filtered): (304184, 24)\n",
      "player_to_predict 统计:\n",
      "player_to_predict\n",
      "True    304184\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n==== Step 2: 过滤 player_to_predict 后 ====\")\n",
    "\n",
    "# 只保留需要预测的球员\n",
    "input_df = input_df[input_df[\"player_to_predict\"] == True].copy()\n",
    "\n",
    "print(\"input_df shape (filtered):\", input_df.shape)\n",
    "print(\"player_to_predict 统计:\")\n",
    "print(input_df[\"player_to_predict\"].value_counts())\n",
    "\n",
    "# 为了方便后面 join，确保类型一致\n",
    "key_cols = [\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"]\n",
    "output_df = output_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d260f47e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:22.392652Z",
     "iopub.status.busy": "2025-11-22T15:32:22.392408Z",
     "iopub.status.idle": "2025-11-22T15:32:22.397600Z",
     "shell.execute_reply": "2025-11-22T15:32:22.396823Z"
    },
    "papermill": {
     "duration": 0.011453,
     "end_time": "2025-11-22T15:32:22.398715",
     "exception": false,
     "start_time": "2025-11-22T15:32:22.387262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mirror_xy(df, direction_col=\"play_direction\"):\n",
    "    df = df.copy()\n",
    "    is_left = df[direction_col] == \"left\"\n",
    "\n",
    "    # 1. x / y 一定要镜像（input / output 都有）\n",
    "    df.loc[is_left, \"x\"] = 120.0 - df.loc[is_left, \"x\"]\n",
    "    df.loc[is_left, \"y\"] = 53.3 - df.loc[is_left, \"y\"]\n",
    "\n",
    "    # 2. 如果有 dir，再镜像 dir\n",
    "    if \"dir\" in df.columns:\n",
    "        df.loc[is_left, \"dir\"] = (180.0 - df.loc[is_left, \"dir\"]) % 360\n",
    "\n",
    "    # 3. 如果有 o，再镜像 o\n",
    "    if \"o\" in df.columns:\n",
    "        df.loc[is_left, \"o\"] = (180.0 - df.loc[is_left, \"o\"]) % 360\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04da06a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:22.408064Z",
     "iopub.status.busy": "2025-11-22T15:32:22.407844Z",
     "iopub.status.idle": "2025-11-22T15:32:22.557204Z",
     "shell.execute_reply": "2025-11-22T15:32:22.556241Z"
    },
    "papermill": {
     "duration": 0.155844,
     "end_time": "2025-11-22T15:32:22.558526",
     "exception": false,
     "start_time": "2025-11-22T15:32:22.402682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Step 3: play_direction 映射检查 ====\n",
      "不同 play_direction 个数: 2\n",
      "play_direction\n",
      "right    1749\n",
      "left     1603\n",
      "Name: count, dtype: int64\n",
      "\n",
      "镜像前后对比 (input_df)：\n",
      "选取 game_id=2023090700, play_id=101 的前 5 行对比：\n",
      "\n",
      "原始：\n",
      "    frame_id play_direction      x      y     dir       o\n",
      "26         1          right  51.32  20.69   79.43  267.68\n",
      "27         2          right  51.35  20.66  118.07  268.66\n",
      "28         3          right  51.39  20.63  130.89  269.78\n",
      "29         4          right  51.43  20.61  134.50  269.78\n",
      "30         5          right  51.48  20.58  129.79  269.06\n",
      "\n",
      "归一化后：\n",
      "    frame_id play_direction      x      y     dir       o\n",
      "26         1          right  51.32  20.69   79.43  267.68\n",
      "27         2          right  51.35  20.66  118.07  268.66\n",
      "28         3          right  51.39  20.63  130.89  269.78\n",
      "29         4          right  51.43  20.61  134.50  269.78\n",
      "30         5          right  51.48  20.58  129.79  269.06\n",
      "\n",
      "output_df 中 play_direction 缺失个数: 0\n",
      "\n",
      "镜像后的 output_df_norm 示例:\n",
      "      game_id  play_id  nfl_id  frame_id      x      y  week play_direction\n",
      "0  2023090700      101   46137         1  56.22  17.28     1          right\n",
      "1  2023090700      101   46137         2  56.63  16.88     1          right\n",
      "2  2023090700      101   46137         3  57.06  16.46     1          right\n",
      "3  2023090700      101   46137         4  57.48  16.02     1          right\n",
      "4  2023090700      101   46137         5  57.91  15.56     1          right\n"
     ]
    }
   ],
   "source": [
    "# 3.1 为每个 play 建立 play_direction 映射\n",
    "play_dir_map = (\n",
    "    input_df[[\"game_id\", \"play_id\", \"play_direction\"]]\n",
    "    .drop_duplicates(subset=[\"game_id\", \"play_id\"])\n",
    "    .set_index([\"game_id\", \"play_id\"])[\"play_direction\"]\n",
    ")\n",
    "\n",
    "print(\"\\n==== Step 3: play_direction 映射检查 ====\")\n",
    "print(\"不同 play_direction 个数:\", play_dir_map.nunique())\n",
    "print(play_dir_map.value_counts())\n",
    "\n",
    "# 3.2 左右归一化函数（你已经定义过的 mirror_xy，直接用）\n",
    "input_df_norm = mirror_xy(input_df, \"play_direction\")\n",
    "\n",
    "print(\"\\n镜像前后对比 (input_df)：\")\n",
    "sample_keys = input_df_norm[[\"game_id\", \"play_id\"]].drop_duplicates().head(1).values[0]\n",
    "g, p = sample_keys\n",
    "print(f\"选取 game_id={g}, play_id={p} 的前 5 行对比：\\n\")\n",
    "\n",
    "print(\"原始：\")\n",
    "print(\n",
    "    input_df[(input_df.game_id==g) & (input_df.play_id==p)]\n",
    "    [[\"frame_id\",\"play_direction\",\"x\",\"y\",\"dir\",\"o\"]].head()\n",
    ")\n",
    "print(\"\\n归一化后：\")\n",
    "print(\n",
    "    input_df_norm[(input_df_norm.game_id==g) & (input_df_norm.play_id==p)]\n",
    "    [[\"frame_id\",\"play_direction\",\"x\",\"y\",\"dir\",\"o\"]].head()\n",
    ")\n",
    "\n",
    "# 3.3 给 output 补上 play_direction 并做同样的镜像\n",
    "output_df_norm = output_df.merge(\n",
    "    play_dir_map.rename(\"play_direction\"),\n",
    "    on=[\"game_id\", \"play_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "missing_dir = output_df_norm[\"play_direction\"].isna().sum()\n",
    "print(\"\\noutput_df 中 play_direction 缺失个数:\", missing_dir)\n",
    "\n",
    "output_df_norm = mirror_xy(output_df_norm, \"play_direction\")\n",
    "\n",
    "print(\"\\n镜像后的 output_df_norm 示例:\")\n",
    "print(output_df_norm.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "982e1ef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:22.569545Z",
     "iopub.status.busy": "2025-11-22T15:32:22.568960Z",
     "iopub.status.idle": "2025-11-22T15:32:22.592881Z",
     "shell.execute_reply": "2025-11-22T15:32:22.592139Z"
    },
    "papermill": {
     "duration": 0.030592,
     "end_time": "2025-11-22T15:32:22.594093",
     "exception": false,
     "start_time": "2025-11-22T15:32:22.563501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_cols: ['x', 'y', 's', 'a', 'dir', 'o', 'ball_land_x', 'ball_land_y']\n",
      "\n",
      "input_df_norm 中这些列的前几行：\n",
      "       game_id  play_id  nfl_id  frame_id      x      y     s     a     dir       o  ball_land_x  ball_land_y\n",
      "26  2023090700      101   46137         1  51.32  20.69  0.31  0.49   79.43  267.68    63.259998        -0.22\n",
      "27  2023090700      101   46137         2  51.35  20.66  0.36  0.74  118.07  268.66    63.259998        -0.22\n",
      "28  2023090700      101   46137         3  51.39  20.63  0.44  0.76  130.89  269.78    63.259998        -0.22\n",
      "29  2023090700      101   46137         4  51.43  20.61  0.48  0.62  134.50  269.78    63.259998        -0.22\n",
      "30  2023090700      101   46137         5  51.48  20.58  0.54  0.44  129.79  269.06    63.259998        -0.22\n",
      "\n",
      "input_df_norm 是否有 NaN:\n",
      "x    0\n",
      "y    0\n",
      "dtype: int64\n",
      "\n",
      "output_df_norm 是否有 NaN:\n",
      "x    0\n",
      "y    0\n",
      "dtype: int64\n",
      "\n",
      "input x/y 范围: 6.45 119.27 0.6899999999999977 52.58\n",
      "output x/y 范围: 11.89 120.83 0.3200000000000003 53.72\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\"x\", \"y\", \"s\", \"a\", \"dir\", \"o\", \"ball_land_x\", \"ball_land_y\"]\n",
    "print(\"\\nfeature_cols:\", feature_cols)\n",
    "\n",
    "print(\"\\ninput_df_norm 中这些列的前几行：\")\n",
    "print(input_df_norm[[\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"] + feature_cols].head())\n",
    "\n",
    "# 检查 NaN / 范围\n",
    "print(\"\\ninput_df_norm 是否有 NaN:\")\n",
    "print(input_df_norm[[\"x\", \"y\"]].isna().sum())\n",
    "\n",
    "print(\"\\noutput_df_norm 是否有 NaN:\")\n",
    "print(output_df_norm[[\"x\", \"y\"]].isna().sum())\n",
    "\n",
    "print(\"\\ninput x/y 范围:\",\n",
    "      input_df_norm[\"x\"].min(), input_df_norm[\"x\"].max(),\n",
    "      input_df_norm[\"y\"].min(), input_df_norm[\"y\"].max())\n",
    "\n",
    "print(\"output x/y 范围:\",\n",
    "      output_df_norm[\"x\"].min(), output_df_norm[\"x\"].max(),\n",
    "      output_df_norm[\"y\"].min(), output_df_norm[\"y\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aa39e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:22.604196Z",
     "iopub.status.busy": "2025-11-22T15:32:22.603932Z",
     "iopub.status.idle": "2025-11-22T15:32:22.614151Z",
     "shell.execute_reply": "2025-11-22T15:32:22.613408Z"
    },
    "papermill": {
     "duration": 0.016733,
     "end_time": "2025-11-22T15:32:22.615291",
     "exception": false,
     "start_time": "2025-11-22T15:32:22.598558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_sequences_with_mask(input_df, output_df, feature_cols, T_in=32, T_out=21):\n",
    "\n",
    "    print(\"\\n==== Step 4: build_sequences (with mask) ====\")\n",
    "\n",
    "    X_list, Y_list, M_list = [], [], []\n",
    "    keys = []\n",
    "\n",
    "    grouped_in  = input_df.groupby([\"game_id\", \"play_id\", \"nfl_id\"])\n",
    "    grouped_out = output_df.groupby([\"game_id\", \"play_id\", \"nfl_id\"])\n",
    "\n",
    "    len_out_counter = {}\n",
    "    dropped_no_output = 0\n",
    "\n",
    "#    total_keys = 0\n",
    "\n",
    "    for key, g_in in grouped_in:\n",
    "        if key not in grouped_out.groups:\n",
    "            continue\n",
    "        g_out = grouped_out.get_group(key)\n",
    "        \n",
    "#        total_keys += 1\n",
    "\n",
    "        # 按 frame_id 排序，保证时间顺序\n",
    "        g_in = g_in.sort_values(\"frame_id\")\n",
    "        g_out = g_out.sort_values(\"frame_id\")\n",
    "\n",
    "        # --- 构造 X 序列 ---\n",
    "        x_feat = g_in[feature_cols].to_numpy(dtype=\"float32\")  # [L_in, F]\n",
    "        L_in, F = x_feat.shape\n",
    "\n",
    "        if L_in >= T_in:\n",
    "            X_seq = x_feat[-T_in:]  # 取最后 T_in 帧\n",
    "        else:\n",
    "            pad_len = T_in - L_in\n",
    "            pad = np.zeros((pad_len, F), dtype=\"float32\")\n",
    "            X_seq = np.concatenate([pad, x_feat], axis=0)\n",
    "\n",
    "        # --- 构造 Y 序列 & mask ---\n",
    "        out_xy = g_out[[\"x\", \"y\"]].to_numpy(dtype=\"float32\")   # [L_out, 2]\n",
    "        L_out = out_xy.shape[0]\n",
    "\n",
    "        len_out_counter[L_out] = len_out_counter.get(L_out, 0) + 1\n",
    "\n",
    "        # 没有任何输出，跳过\n",
    "        if L_out == 0:\n",
    "            dropped_no_output += 1\n",
    "            continue\n",
    "\n",
    "        if L_out >= T_out:\n",
    "            Y_seq = out_xy[:T_out]\n",
    "            mask = np.ones(T_out, dtype=\"float32\")\n",
    "        else:\n",
    "            # 用最后一帧的位置重复填充\n",
    "            last_xy = out_xy[-1]\n",
    "            pad_len = T_out - L_out\n",
    "            pad_xy = np.repeat(last_xy[None, :], pad_len, axis=0)  # [pad_len, 2]\n",
    "            Y_seq = np.concatenate([out_xy, pad_xy], axis=0)\n",
    "\n",
    "            mask = np.concatenate([\n",
    "                np.ones(L_out, dtype=\"float32\"),\n",
    "                np.zeros(pad_len, dtype=\"float32\"),\n",
    "            ], axis=0)  # [T_out]\n",
    "\n",
    "        X_list.append(X_seq)\n",
    "        Y_list.append(Y_seq)\n",
    "        M_list.append(mask)\n",
    "        keys.append(key)\n",
    "\n",
    "    # 堆叠成 ndarray\n",
    "    X_all = np.stack(X_list, axis=0)\n",
    "    Y_all = np.stack(Y_list, axis=0)\n",
    "    M_all = np.stack(M_list, axis=0)\n",
    "\n",
    "    print(\"共有样本 key 数:\", len(keys))\n",
    "    print(\"build_sequences 完成:\")\n",
    "    print(\"X_all shape:\", X_all.shape)  # 期望 [N, T_in, F]\n",
    "    print(\"Y_all shape:\", Y_all.shape)  # 期望 [N, T_out, 2]\n",
    "    print(\"M_all shape:\", M_all.shape)  # 期望 [N, T_out]\")\n",
    "\n",
    "    print(\"\\n被丢弃的样本（L_out == 0）数量:\", dropped_no_output)\n",
    "\n",
    "    print(\"\\n输出长度分布 (原始 L_out):\")\n",
    "    for L_out in sorted(len_out_counter.keys()):\n",
    "        print(f\"  len_out = {L_out}: {len_out_counter[L_out]} 条\")\n",
    "\n",
    "    # 打印一个样本看一下\n",
    "    if X_all.shape[0] > 0:\n",
    "        print(\"\\n示例样本 0:\")\n",
    "        print(\"X_all[0] 前 3 帧:\\n\", X_all[0, :3])\n",
    "        print(\"Y_all[0] 前 3 帧:\\n\", Y_all[0, :3])\n",
    "        print(\"M_all[0]:\\n\", M_all[0])\n",
    "\n",
    "    return X_all, Y_all, M_all, keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833fe0c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:22.625043Z",
     "iopub.status.busy": "2025-11-22T15:32:22.624658Z",
     "iopub.status.idle": "2025-11-22T15:32:35.078733Z",
     "shell.execute_reply": "2025-11-22T15:32:35.077848Z"
    },
    "papermill": {
     "duration": 12.460635,
     "end_time": "2025-11-22T15:32:35.080202",
     "exception": false,
     "start_time": "2025-11-22T15:32:22.619567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Step 4: build_sequences (with mask) ====\n",
      "共有样本 key 数: 10913\n",
      "build_sequences 完成:\n",
      "X_all shape: (10913, 32, 8)\n",
      "Y_all shape: (10913, 21, 2)\n",
      "M_all shape: (10913, 21)\n",
      "\n",
      "被丢弃的样本（L_out == 0）数量: 0\n",
      "\n",
      "输出长度分布 (原始 L_out):\n",
      "  len_out = 5: 61 条\n",
      "  len_out = 6: 391 条\n",
      "  len_out = 7: 1152 条\n",
      "  len_out = 8: 1450 条\n",
      "  len_out = 9: 1389 条\n",
      "  len_out = 10: 1319 条\n",
      "  len_out = 11: 906 条\n",
      "  len_out = 12: 815 条\n",
      "  len_out = 13: 586 条\n",
      "  len_out = 14: 464 条\n",
      "  len_out = 15: 357 条\n",
      "  len_out = 16: 284 条\n",
      "  len_out = 17: 249 条\n",
      "  len_out = 18: 204 条\n",
      "  len_out = 19: 197 条\n",
      "  len_out = 20: 143 条\n",
      "  len_out = 21: 102 条\n",
      "  len_out = 22: 125 条\n",
      "  len_out = 23: 166 条\n",
      "  len_out = 24: 110 条\n",
      "  len_out = 25: 68 条\n",
      "  len_out = 26: 111 条\n",
      "  len_out = 27: 67 条\n",
      "  len_out = 28: 58 条\n",
      "  len_out = 29: 39 条\n",
      "  len_out = 30: 38 条\n",
      "  len_out = 31: 11 条\n",
      "  len_out = 32: 10 条\n",
      "  len_out = 33: 3 条\n",
      "  len_out = 34: 19 条\n",
      "  len_out = 36: 4 条\n",
      "  len_out = 40: 7 条\n",
      "  len_out = 94: 8 条\n",
      "\n",
      "示例样本 0:\n",
      "X_all[0] 前 3 帧:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Y_all[0] 前 3 帧:\n",
      " [[53.2  13.98]\n",
      " [53.96 13.78]\n",
      " [54.7  13.54]]\n",
      "M_all[0]:\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "==== Step 4: build_sequences ====\n",
      "共有样本 key 数: 10913\n",
      "X_all shape: (10913, 32, 8)\n",
      "Y_all shape: (10913, 21, 2)\n",
      "M_all Shape: (10913, 21)\n"
     ]
    }
   ],
   "source": [
    "T_in  = 32\n",
    "T_out = 21\n",
    "\n",
    "X_all, Y_all, M_all, keys = build_sequences_with_mask(\n",
    "    input_df_norm,\n",
    "    output_df_norm,\n",
    "    feature_cols,\n",
    "    T_in=T_in,\n",
    "    T_out=T_out,\n",
    ")\n",
    "print(\"\\n==== Step 4: build_sequences ====\")\n",
    "print(\"共有样本 key 数:\", len(X_all))\n",
    "print(\"X_all shape:\", X_all.shape)  # 期望 (N, 32, F)\n",
    "print(\"Y_all shape:\", Y_all.shape)  # 期望 (N, 21, 2)\n",
    "print(\"M_all Shape:\",  M_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b6428e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:35.090759Z",
     "iopub.status.busy": "2025-11-22T15:32:35.090525Z",
     "iopub.status.idle": "2025-11-22T15:32:35.105907Z",
     "shell.execute_reply": "2025-11-22T15:32:35.105213Z"
    },
    "papermill": {
     "duration": 0.021655,
     "end_time": "2025-11-22T15:32:35.106988",
     "exception": false,
     "start_time": "2025-11-22T15:32:35.085333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 8730\n",
      "Val   size: 2183\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = len(keys)\n",
    "keys = np.array(keys)\n",
    "\n",
    "# 随机打乱索引\n",
    "rng = np.random.default_rng(42)\n",
    "perm = rng.permutation(N)\n",
    "\n",
    "split = int(N * 0.8)   # 80% 训练，20% 验证\n",
    "train_idx = perm[:split]\n",
    "val_idx   = perm[split:]\n",
    "\n",
    "X_train, Y_train, M_train = X_all[train_idx], Y_all[train_idx], M_all[train_idx]\n",
    "X_val,   Y_val,   M_val   = X_all[val_idx],   Y_all[val_idx],   M_all[val_idx]\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0])\n",
    "print(\"Val   size:\", X_val.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42a16cec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:35.117050Z",
     "iopub.status.busy": "2025-11-22T15:32:35.116836Z",
     "iopub.status.idle": "2025-11-22T15:32:35.122761Z",
     "shell.execute_reply": "2025-11-22T15:32:35.122013Z"
    },
    "papermill": {
     "duration": 0.012298,
     "end_time": "2025-11-22T15:32:35.124045",
     "exception": false,
     "start_time": "2025-11-22T15:32:35.111747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y, M):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.M = M\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.from_numpy(self.X[idx]).float(),\n",
    "            torch.from_numpy(self.Y[idx]).float(),\n",
    "            torch.from_numpy(self.M[idx]).float(),\n",
    "        )\n",
    "\n",
    "def build_loader(X, Y, M, batch_size=64, shuffle=True):\n",
    "    dataset = Seq2SeqDataset(X, Y, M)\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # 检查一批\n",
    "    for i, (xb, yb, mb) in enumerate(loader):\n",
    "        print(\"First batch idx:\", i)\n",
    "        print(\" xb shape:\", xb.shape)  # [B, 32, F]\n",
    "        print(\" yb shape:\", yb.shape)  # [B, 21, 2]\n",
    "        print(\" mb shape:\", mb.shape)  # [B, 21]\n",
    "        break\n",
    "\n",
    "    return loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdbab46d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:35.133749Z",
     "iopub.status.busy": "2025-11-22T15:32:35.133551Z",
     "iopub.status.idle": "2025-11-22T15:32:35.196686Z",
     "shell.execute_reply": "2025-11-22T15:32:35.195921Z"
    },
    "papermill": {
     "duration": 0.069183,
     "end_time": "2025-11-22T15:32:35.197810",
     "exception": false,
     "start_time": "2025-11-22T15:32:35.128627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch idx: 0\n",
      " xb shape: torch.Size([64, 32, 8])\n",
      " yb shape: torch.Size([64, 21, 2])\n",
      " mb shape: torch.Size([64, 21])\n",
      "First batch idx: 0\n",
      " xb shape: torch.Size([64, 32, 8])\n",
      " yb shape: torch.Size([64, 21, 2])\n",
      " mb shape: torch.Size([64, 21])\n"
     ]
    }
   ],
   "source": [
    "train_loader = build_loader(X_train, Y_train, M_train, batch_size=64, shuffle=True)\n",
    "val_loader   = build_loader(X_val,   Y_val,   M_val,   batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba8edd5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:35.208877Z",
     "iopub.status.busy": "2025-11-22T15:32:35.208650Z",
     "iopub.status.idle": "2025-11-22T15:32:35.220856Z",
     "shell.execute_reply": "2025-11-22T15:32:35.220373Z"
    },
    "papermill": {
     "duration": 0.019136,
     "end_time": "2025-11-22T15:32:35.221818",
     "exception": false,
     "start_time": "2025-11-22T15:32:35.202682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# =========================\n",
    "# Positional Encoding\n",
    "# =========================\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 64):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2, dtype=torch.float32)\n",
    "            * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # [1, max_len, d_model]\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [B, T, d_model]\n",
    "        T = x.size(1)\n",
    "        return x + self.pe[:, :T, :]\n",
    "        \n",
    "\n",
    "# =========================\n",
    "# 自回归 Transformer 模型\n",
    "# 输入: [B, T_in, F]\n",
    "# 输出: [B, T_out, 2]  (未来每一帧的 x,y)\n",
    "# =========================\n",
    "class AutoRegressiveTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        d_model: int = 128,\n",
    "        nhead: int = 4,\n",
    "        num_layers: int = 3,\n",
    "        T_in: int = 32,\n",
    "        T_out: int = 21,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.T_out = T_out\n",
    "\n",
    "        # 编码器：把输入特征映射到 d_model\n",
    "        self.input_fc = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len=T_in + T_out)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=4 * d_model,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "\n",
    "        # 解码器：一步步用“上一时刻位置”生成下一时刻位置\n",
    "        dec_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=4 * d_model,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(dec_layer, num_layers=num_layers)\n",
    "\n",
    "        # 把上一步的 (x,y) 位置映射到 d_model 作为 decoder 输入\n",
    "        self.query_fc = nn.Linear(2, d_model)\n",
    "\n",
    "        # 输出层：d_model -> (x,y)\n",
    "        self.out_fc = nn.Linear(d_model, 2)\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, size: int, device):\n",
    "        # 上三角为 -inf 的注意力 mask，保证自回归\n",
    "        mask = torch.triu(\n",
    "            torch.full((size, size), float(\"-inf\"), device=device), diagonal=1\n",
    "        )\n",
    "        return mask\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src: torch.Tensor,           # [B, T_in, F]\n",
    "        target: torch.Tensor = None, # [B, T_out, 2]  (训练时可选)\n",
    "        teacher_forcing_ratio: float = 0.0,\n",
    "    ) -> torch.Tensor:\n",
    "        B, T_in, _ = src.shape\n",
    "        device = src.device\n",
    "\n",
    "        # ===== 编码器 =====\n",
    "        src_embed = self.input_fc(src)          # [B, T_in, d_model]\n",
    "        src_embed = self.pos_encoder(src_embed)\n",
    "        memory = self.encoder(src_embed)        # [B, T_in, d_model]\n",
    "\n",
    "        # 最后一帧已观测位置 (注意：feature_cols 的前两列是 x,y)\n",
    "        last_pos = src[:, -1, :2]               # [B, 2]\n",
    "\n",
    "        outputs = []\n",
    "        dec_inputs = []\n",
    "\n",
    "        for t in range(self.T_out):\n",
    "            # 决定当前步使用什么“上一位置”作为输入\n",
    "            if t == 0:\n",
    "                prev_pos = last_pos             # 第一步：用观测的最后一帧位置\n",
    "            else:\n",
    "                use_teacher = (\n",
    "                    (target is not None)\n",
    "                    and (teacher_forcing_ratio > 0)\n",
    "                    and (torch.rand(1).item() < teacher_forcing_ratio)\n",
    "                )\n",
    "                if use_teacher:\n",
    "                    # Teacher Forcing：用真值的上一步位置\n",
    "                    prev_pos = target[:, t - 1, :]   # [B, 2]\n",
    "                else:\n",
    "                    # 自回归：用模型预测的上一帧\n",
    "                    prev_pos = outputs[-1]          # [B, 2]\n",
    "\n",
    "            dec_inputs.append(prev_pos.unsqueeze(1))   # [B, 1, 2]\n",
    "            dec_seq = torch.cat(dec_inputs, dim=1)     # [B, t+1, 2]\n",
    "\n",
    "            dec_embed = self.query_fc(dec_seq)         # [B, t+1, d_model]\n",
    "            dec_embed = self.pos_encoder(dec_embed)\n",
    "\n",
    "            tgt_mask = self._generate_square_subsequent_mask(\n",
    "                dec_embed.size(1), device\n",
    "            )\n",
    "\n",
    "            dec_out = self.decoder(\n",
    "                dec_embed, memory, tgt_mask=tgt_mask\n",
    "            )                                          # [B, t+1, d_model]\n",
    "\n",
    "            step_out = self.out_fc(dec_out[:, -1, :])  # 只取最后一帧 [B, 2]\n",
    "            outputs.append(step_out)\n",
    "\n",
    "        outputs = torch.stack(outputs, dim=1)          # [B, T_out, 2]\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "647ed7d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:35.231800Z",
     "iopub.status.busy": "2025-11-22T15:32:35.231251Z",
     "iopub.status.idle": "2025-11-22T15:32:40.055244Z",
     "shell.execute_reply": "2025-11-22T15:32:40.054610Z"
    },
    "papermill": {
     "duration": 4.830322,
     "end_time": "2025-11-22T15:32:40.056635",
     "exception": false,
     "start_time": "2025-11-22T15:32:35.226313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "input_dim = X_all.shape[-1]      # 8\n",
    "d_model   = 128\n",
    "\n",
    "model = AutoRegressiveTransformer(\n",
    "    input_dim=input_dim,\n",
    "    d_model=d_model,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0c34c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:40.067825Z",
     "iopub.status.busy": "2025-11-22T15:32:40.067072Z",
     "iopub.status.idle": "2025-11-22T15:32:40.073004Z",
     "shell.execute_reply": "2025-11-22T15:32:40.072281Z"
    },
    "papermill": {
     "duration": 0.012501,
     "end_time": "2025-11-22T15:32:40.074055",
     "exception": false,
     "start_time": "2025-11-22T15:32:40.061554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, clip_grad=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "\n",
    "    for Xb, Yb, Mb in loader:\n",
    "        Xb = Xb.to(device)          # [B, 32, F]\n",
    "        Yb = Yb.to(device)          # [B, 21, 2]\n",
    "        Mb = Mb.to(device)          # [B, 21]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 最后一帧观测位置\n",
    "        last_pos = Xb[:, -1, :2]    # [B, 2]\n",
    "\n",
    "        # 预测相对位移\n",
    "        preds_rel = model(Xb)       # [B, 21, 2]\n",
    "        preds_abs = preds_rel + last_pos.unsqueeze(1)\n",
    "\n",
    "        # 只在有效帧上算 MSE\n",
    "        diff = preds_abs - Yb                    # [B, 21, 2]\n",
    "        diff = diff * Mb.unsqueeze(-1)           # mask 掉 padding\n",
    "        se = (diff ** 2).sum()                   # 总平方误差\n",
    "        cnt = Mb.sum() * 2.0                     # 有效坐标个数 (x,y)\n",
    "\n",
    "        loss = se / cnt\n",
    "        loss.backward()\n",
    "\n",
    "        if clip_grad is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_count += 1\n",
    "\n",
    "    return total_loss / max(total_count, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "625003d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:40.084851Z",
     "iopub.status.busy": "2025-11-22T15:32:40.084297Z",
     "iopub.status.idle": "2025-11-22T15:32:40.089244Z",
     "shell.execute_reply": "2025-11-22T15:32:40.088756Z"
    },
    "papermill": {
     "duration": 0.011189,
     "end_time": "2025-11-22T15:32:40.090314",
     "exception": false,
     "start_time": "2025-11-22T15:32:40.079125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_rmse_on_loader(model, loader):\n",
    "    model.eval()\n",
    "    se_sum = 0.0\n",
    "    n = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for Xb, Yb, Mb in loader:\n",
    "            Xb = Xb.to(device)\n",
    "            Yb = Yb.to(device)\n",
    "            Mb = Mb.to(device)\n",
    "\n",
    "            last_pos = Xb[:, -1, :2]\n",
    "            preds_rel = model(Xb)\n",
    "            preds_abs = preds_rel + last_pos.unsqueeze(1)\n",
    "\n",
    "            diff = preds_abs - Yb           # [B, 21, 2]\n",
    "            diff = diff * Mb.unsqueeze(-1)  # 只算有效帧\n",
    "\n",
    "            dist2 = diff[..., 0]**2 + diff[..., 1]**2   # [B, 21]\n",
    "            se_sum += dist2.sum().item()\n",
    "            n += Mb.sum().item()\n",
    "\n",
    "    rmse = math.sqrt(se_sum / max(n, 1.0))\n",
    "    print(f\"RMSE on this loader (yards): {rmse:.4f}\")\n",
    "    model.train()\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "012a985c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:32:40.100660Z",
     "iopub.status.busy": "2025-11-22T15:32:40.100246Z",
     "iopub.status.idle": "2025-11-22T15:41:43.908769Z",
     "shell.execute_reply": "2025-11-22T15:41:43.907942Z"
    },
    "papermill": {
     "duration": 543.815191,
     "end_time": "2025-11-22T15:41:43.910010",
     "exception": false,
     "start_time": "2025-11-22T15:32:40.094819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 | Train Loss = 8.7348\n",
      "RMSE on this loader (yards): 3.7196\n",
      "           Val RMSE   = 3.7196\n",
      "  ✅ New best model saved. RMSE = 3.7196\n",
      "Epoch 2/15 | Train Loss = 7.1540\n",
      "RMSE on this loader (yards): 3.6022\n",
      "           Val RMSE   = 3.6022\n",
      "  ✅ New best model saved. RMSE = 3.6022\n",
      "Epoch 3/15 | Train Loss = 6.2367\n",
      "RMSE on this loader (yards): 3.3547\n",
      "           Val RMSE   = 3.3547\n",
      "  ✅ New best model saved. RMSE = 3.3547\n",
      "Epoch 4/15 | Train Loss = 5.8089\n",
      "RMSE on this loader (yards): 3.2268\n",
      "           Val RMSE   = 3.2268\n",
      "  ✅ New best model saved. RMSE = 3.2268\n",
      "Epoch 5/15 | Train Loss = 5.4418\n",
      "RMSE on this loader (yards): 3.2654\n",
      "           Val RMSE   = 3.2654\n",
      "Epoch 6/15 | Train Loss = 5.1426\n",
      "RMSE on this loader (yards): 3.0987\n",
      "           Val RMSE   = 3.0987\n",
      "  ✅ New best model saved. RMSE = 3.0987\n",
      "Epoch 7/15 | Train Loss = 4.9121\n",
      "RMSE on this loader (yards): 2.9872\n",
      "           Val RMSE   = 2.9872\n",
      "  ✅ New best model saved. RMSE = 2.9872\n",
      "Epoch 8/15 | Train Loss = 4.6254\n",
      "RMSE on this loader (yards): 3.0971\n",
      "           Val RMSE   = 3.0971\n",
      "Epoch 9/15 | Train Loss = 4.5279\n",
      "RMSE on this loader (yards): 2.8955\n",
      "           Val RMSE   = 2.8955\n",
      "  ✅ New best model saved. RMSE = 2.8955\n",
      "Epoch 10/15 | Train Loss = 4.2766\n",
      "RMSE on this loader (yards): 2.9504\n",
      "           Val RMSE   = 2.9504\n",
      "Epoch 11/15 | Train Loss = 4.1519\n",
      "RMSE on this loader (yards): 2.8828\n",
      "           Val RMSE   = 2.8828\n",
      "  ✅ New best model saved. RMSE = 2.8828\n",
      "Epoch 12/15 | Train Loss = 3.9513\n",
      "RMSE on this loader (yards): 2.8537\n",
      "           Val RMSE   = 2.8537\n",
      "  ✅ New best model saved. RMSE = 2.8537\n",
      "Epoch 13/15 | Train Loss = 3.8531\n",
      "RMSE on this loader (yards): 2.6886\n",
      "           Val RMSE   = 2.6886\n",
      "  ✅ New best model saved. RMSE = 2.6886\n",
      "Epoch 14/15 | Train Loss = 3.7706\n",
      "RMSE on this loader (yards): 2.7765\n",
      "           Val RMSE   = 2.7765\n",
      "Epoch 15/15 | Train Loss = 3.6309\n",
      "RMSE on this loader (yards): 2.7551\n",
      "           Val RMSE   = 2.7551\n",
      "\n",
      "Loaded best model with RMSE = 2.6886\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=20, clip_grad=1.0):\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, clip_grad)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} | Train Loss = {train_loss:.4f}\")\n",
    "\n",
    "        val_rmse = compute_rmse_on_loader(model, val_loader)\n",
    "        print(f\"           Val RMSE   = {val_rmse:.4f}\")\n",
    "\n",
    "        if val_rmse < best_rmse:\n",
    "            best_rmse = val_rmse\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_state, \"/kaggle/working/model_autoreg_best.pt\")\n",
    "            print(f\"  ✅ New best model saved. RMSE = {best_rmse:.4f}\")\n",
    "\n",
    "    # 训练结束后，加载最佳权重\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "        print(f\"\\nLoaded best model with RMSE = {best_rmse:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# 真正开始训练\n",
    "model = train_model(model, train_loader, val_loader, epochs=15, clip_grad=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da4092ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:41:43.923167Z",
     "iopub.status.busy": "2025-11-22T15:41:43.922916Z",
     "iopub.status.idle": "2025-11-22T15:41:43.931066Z",
     "shell.execute_reply": "2025-11-22T15:41:43.930543Z"
    },
    "papermill": {
     "duration": 0.016128,
     "end_time": "2025-11-22T15:41:43.932170",
     "exception": false,
     "start_time": "2025-11-22T15:41:43.916042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "########\n",
    "## For Prediction\n",
    "########\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "T_IN  = 32\n",
    "T_OUT = 21\n",
    "\n",
    "FEATURE_COLS = [\"x\", \"y\", \"s\", \"a\", \"dir\", \"o\", \"ball_land_x\", \"ball_land_y\"]\n",
    "MODEL_PATH   = \"/kaggle/working/model_autoreg_best.pt\"   # 和训练时保持一致\n",
    "\n",
    "\n",
    "def mirror_xy(df: pd.DataFrame, direction_col: str = \"play_direction\") -> pd.DataFrame:\n",
    "    \"\"\"把所有 left 进攻的路线镜像成 right（和训练时完全一致）\"\"\"\n",
    "    df = df.copy()\n",
    "    is_left = df[direction_col] == \"left\"\n",
    "\n",
    "    df.loc[is_left, \"x\"]   = 120.0 - df.loc[is_left, \"x\"]\n",
    "    df.loc[is_left, \"y\"]   = 53.3  - df.loc[is_left, \"y\"]\n",
    "    df.loc[is_left, \"dir\"] = (180.0 - df.loc[is_left, \"dir\"]) % 360.0\n",
    "    df.loc[is_left, \"o\"]   = (180.0 - df.loc[is_left, \"o\"])   % 360.0\n",
    "    return df\n",
    "\n",
    "\n",
    "def unmirror_xy_xy_array(xy: np.ndarray, is_left: bool) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    把预测结果从“全是向右进攻的坐标系”翻回原始坐标系。\n",
    "    xy: [T, 2]\n",
    "    \"\"\"\n",
    "    if not is_left:\n",
    "        return xy\n",
    "\n",
    "    out = xy.copy()\n",
    "    out[:, 0] = 120.0 - out[:, 0]\n",
    "    out[:, 1] = 53.3  - out[:, 1]\n",
    "    return out\n",
    "\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    \"\"\"只用 X 的简单 Dataset，用在 DataLoader 里做 batch 推理。\"\"\"\n",
    "    def __init__(self, X_all: np.ndarray):\n",
    "        self.X = torch.from_numpy(X_all).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d46a452f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:41:43.944637Z",
     "iopub.status.busy": "2025-11-22T15:41:43.944256Z",
     "iopub.status.idle": "2025-11-22T15:41:43.951017Z",
     "shell.execute_reply": "2025-11-22T15:41:43.950346Z"
    },
    "papermill": {
     "duration": 0.014144,
     "end_time": "2025-11-22T15:41:43.952033",
     "exception": false,
     "start_time": "2025-11-22T15:41:43.937889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 和训练时保持一致\n",
    "T_in = 32\n",
    "T_out = 21\n",
    "feature_cols = ['x', 'y', 's', 'a', 'dir', 'o', 'ball_land_x', 'ball_land_y']\n",
    "\n",
    "def build_test_sequences(input_df_norm, feature_cols, T_in=32, T_out=21):\n",
    "\n",
    "    X_list = []\n",
    "    last_pos_list = []\n",
    "    len_out_list = []\n",
    "    key_list = []\n",
    "    play_dirs = []\n",
    "\n",
    "    grp = input_df_norm.groupby([\"game_id\", \"play_id\", \"nfl_id\"])\n",
    "    for (g, p, n), df in grp:\n",
    "        df = df.sort_values(\"frame_id\")\n",
    "\n",
    "        feats = df[feature_cols].to_numpy(dtype=np.float32)   # [L_in, F]\n",
    "        L_in = feats.shape[0]\n",
    "        F = feats.shape[1]\n",
    "\n",
    "        # 左侧用 0 填充，保证长度 = T_in\n",
    "        x_seq = np.zeros((T_in, F), dtype=np.float32)\n",
    "        if L_in >= T_in:\n",
    "            x_seq[:] = feats[-T_in:]\n",
    "        else:\n",
    "            x_seq[-L_in:, :] = feats\n",
    "\n",
    "        X_list.append(x_seq)\n",
    "        last_pos_list.append(feats[-1, :2])  # 最后一个观测点 (x,y)\n",
    "        len_out_list.append(int(df[\"num_frames_output\"].iloc[0]))\n",
    "        key_list.append((g, p, n))\n",
    "        play_dirs.append(df[\"play_direction\"].iloc[0])\n",
    "\n",
    "    X_all = np.stack(X_list)                   # [N, T_in, F]\n",
    "    last_pos = np.stack(last_pos_list)         # [N, 2]\n",
    "    lens_out = np.asarray(len_out_list, int)   # [N]\n",
    "\n",
    "    return X_all, last_pos, lens_out, key_list, play_dirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69c8a397",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:41:43.964673Z",
     "iopub.status.busy": "2025-11-22T15:41:43.964466Z",
     "iopub.status.idle": "2025-11-22T15:41:43.971046Z",
     "shell.execute_reply": "2025-11-22T15:41:43.970330Z"
    },
    "papermill": {
     "duration": 0.014391,
     "end_time": "2025-11-22T15:41:43.972073",
     "exception": false,
     "start_time": "2025-11-22T15:41:43.957682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import polars as pl\n",
    "\n",
    "# 1. 方向特征（跟训练时一样）\n",
    "def add_direction_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    rad_dir = np.deg2rad(df[\"dir\"].astype(float))\n",
    "    rad_o   = np.deg2rad(df[\"o\"].astype(float))\n",
    "    df[\"dir_sin\"] = np.sin(rad_dir)\n",
    "    df[\"dir_cos\"] = np.cos(rad_dir)\n",
    "    df[\"o_sin\"]   = np.sin(rad_o)\n",
    "    df[\"o_cos\"]   = np.cos(rad_o)\n",
    "    return df\n",
    "\n",
    "# 2. 左右归一化（跟训练时的 mirror_xy / normalize_direction 一致）\n",
    "def normalize_direction(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    is_left = df[\"play_direction\"] == \"left\"\n",
    "\n",
    "    df.loc[is_left, \"x\"] = 120.0 - df.loc[is_left, \"x\"]\n",
    "    df.loc[is_left, \"y\"] =  53.3 - df.loc[is_left, \"y\"]\n",
    "\n",
    "    df.loc[is_left, \"dir\"] = (180.0 - df.loc[is_left, \"dir\"]) % 360\n",
    "    df.loc[is_left, \"o\"]   = (180.0 - df.loc[is_left, \"o\"]) % 360\n",
    "\n",
    "    return df\n",
    "\n",
    "# 3. 把「统一向右」的预测坐标还原回原始方向\n",
    "def denormalize_xy(xy: np.ndarray, play_direction: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    xy: [T, 2]  在统一向右坐标系下的预测\n",
    "    play_direction: 'left' 或 'right'（原始的）\n",
    "    \"\"\"\n",
    "    if play_direction == \"left\":\n",
    "        xy = xy.copy()\n",
    "        xy[:, 0] = 120.0 - xy[:, 0]\n",
    "        xy[:, 1] =  53.3 - xy[:, 1]\n",
    "    return xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8be01cbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:41:43.984388Z",
     "iopub.status.busy": "2025-11-22T15:41:43.983910Z",
     "iopub.status.idle": "2025-11-22T15:41:43.990110Z",
     "shell.execute_reply": "2025-11-22T15:41:43.989388Z"
    },
    "papermill": {
     "duration": 0.013504,
     "end_time": "2025-11-22T15:41:43.991150",
     "exception": false,
     "start_time": "2025-11-22T15:41:43.977646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# ========= 常量（要和训练时保持一致） =========\n",
    "T_IN = 32\n",
    "T_OUT = 21\n",
    "\n",
    "feature_cols = [\n",
    "    \"x\", \"y\", \"s\", \"a\", \"dir\", \"o\",\n",
    "    \"ball_land_x\", \"ball_land_y\",\n",
    "]\n",
    "\n",
    "BEST_MODEL_PATH = \"/kaggle/working/model_autoreg_best.pt\"\n",
    "\n",
    "# 全局的 device 和 model，避免每个 batch 反复 load\n",
    "_PREDICT_DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "_PREDICT_MODEL = None\n",
    "\n",
    "\n",
    "# ========= 如果前面已经有同名函数，可以只保留一份 =========\n",
    "def load_trained_model(device: torch.device):\n",
    "    \"\"\"和训练时一样的模型定义 + load_state_dict\"\"\"\n",
    "    d_model = 128\n",
    "    nhead = 8\n",
    "    num_layers = 3\n",
    "\n",
    "    model = AutoRegressiveTransformer(\n",
    "        input_dim=len(feature_cols),\n",
    "        d_model=d_model,\n",
    "        nhead=nhead,\n",
    "        num_layers=num_layers,\n",
    "        T_in=T_IN,\n",
    "        T_out=T_OUT,\n",
    "    ).to(device)\n",
    "\n",
    "    state = torch.load(BEST_MODEL_PATH, map_location=device)\n",
    "    state_dict = state[\"model\"] if isinstance(state, dict) and \"model\" in state else state\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_predict_model():\n",
    "    global _PREDICT_MODEL\n",
    "    if _PREDICT_MODEL is None:\n",
    "        _PREDICT_MODEL = load_trained_model(_PREDICT_DEVICE)\n",
    "    return _PREDICT_MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83c92cf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:41:44.003813Z",
     "iopub.status.busy": "2025-11-22T15:41:44.003214Z",
     "iopub.status.idle": "2025-11-22T15:41:44.007441Z",
     "shell.execute_reply": "2025-11-22T15:41:44.006867Z"
    },
    "papermill": {
     "duration": 0.011733,
     "end_time": "2025-11-22T15:41:44.008462",
     "exception": false,
     "start_time": "2025-11-22T15:41:43.996729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unmirror_xy_for_output(preds_abs: np.ndarray, play_dirs: np.ndarray):\n",
    "    \"\"\"\n",
    "    把右向坐标预测 (preds_abs) 反镜像回原始的左右方向。\n",
    "\n",
    "    preds_abs: [N, T_out, 2] 预测的 x,y（都是右向坐标）\n",
    "    play_dirs: [N] 方向标签，元素为 'left' 或 'right'\n",
    "    \"\"\"\n",
    "    preds = preds_abs.copy()\n",
    "    for i, d in enumerate(play_dirs):\n",
    "        if d == \"left\":\n",
    "            preds[i, :, 0] = 120.0 - preds[i, :, 0]\n",
    "            preds[i, :, 1] = 53.3 - preds[i, :, 1]\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8f1e5f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:41:44.021099Z",
     "iopub.status.busy": "2025-11-22T15:41:44.020501Z",
     "iopub.status.idle": "2025-11-22T15:41:44.028782Z",
     "shell.execute_reply": "2025-11-22T15:41:44.028020Z"
    },
    "papermill": {
     "duration": 0.015729,
     "end_time": "2025-11-22T15:41:44.029811",
     "exception": false,
     "start_time": "2025-11-22T15:41:44.014082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pd.DataFrame:\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = get_predict_model()   # 你的加载函数\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # --- 1. Polars → Pandas\n",
    "    test_df = test.to_pandas()\n",
    "    input_df = test_input.to_pandas()\n",
    "\n",
    "    # --- 2. 添加方向 sin/cos、mirror（与训练完全一致）\n",
    "    input_df = add_direction_features(input_df)\n",
    "    input_df = normalize_direction(input_df)\n",
    "\n",
    "    # --- 3. 构造输入序列\n",
    "    X_all, last_pos, lens_out, key_list, play_dirs = build_test_sequences(\n",
    "        input_df, feature_cols, T_in=T_IN, T_out=T_OUT\n",
    "    )\n",
    "\n",
    "    # --- 4. 模型前向\n",
    "    X_tensor = torch.from_numpy(X_all).float().to(device)\n",
    "    with torch.no_grad():\n",
    "        preds_rel = model(X_tensor).cpu().numpy()   # [N, T_out, 2]\n",
    "\n",
    "    preds_abs = preds_rel + last_pos[:, None, :]    # [N, T_out, 2]\n",
    "\n",
    "    # --- 5. 反mirror（恢复 left/right 原始方向）\n",
    "    preds_abs = unmirror_xy_for_output(preds_abs, play_dirs)\n",
    "\n",
    "    # --- 6. 展平成一条条\n",
    "    merged = []\n",
    "\n",
    "    for idx, (g,p,n) in enumerate(key_list):\n",
    "        # 当前 sample 要输出多少行\n",
    "        needed = len(test_df[(test_df[\"game_id\"]==g)&(test_df[\"play_id\"]==p)&(test_df[\"nfl_id\"]==n)])\n",
    "\n",
    "        cur = preds_abs[idx]   # [T_out,2]\n",
    "\n",
    "        if needed <= T_OUT:\n",
    "            out = cur[:needed]\n",
    "        else:\n",
    "            # 多出的 frame_id → 用最后一帧填充\n",
    "            pad = np.repeat(cur[-1:,:], needed-T_OUT, axis=0)\n",
    "            out = np.vstack([cur, pad])\n",
    "\n",
    "        df = test_df[(test_df[\"game_id\"]==g)&(test_df[\"play_id\"]==p)&(test_df[\"nfl_id\"]==n)].copy()\n",
    "        df[\"x\"] = out[:,0]\n",
    "        df[\"y\"] = out[:,1]\n",
    "        merged.append(df)\n",
    "\n",
    "    final = pd.concat(merged, ignore_index=True)\n",
    "\n",
    "    # 保证顺序一致\n",
    "    final = final.sort_values([\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"])\n",
    "\n",
    "    return final[[\"x\",\"y\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fff7c5af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T15:41:44.042213Z",
     "iopub.status.busy": "2025-11-22T15:41:44.041643Z",
     "iopub.status.idle": "2025-11-22T15:42:01.571302Z",
     "shell.execute_reply": "2025-11-22T15:42:01.570500Z"
    },
    "papermill": {
     "duration": 17.537414,
     "end_time": "2025-11-22T15:42:01.572711",
     "exception": false,
     "start_time": "2025-11-22T15:41:44.035297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Inference ready.\n"
     ]
    }
   ],
   "source": [
    "from kaggle_evaluation import nfl_inference_server\n",
    "inference_server = nfl_inference_server.NFLInferenceServer(predict)\n",
    "\n",
    "if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway((\"/kaggle/input/nfl-big-data-bowl-2026-prediction\",))\n",
    "print(\"🚀 Inference ready.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14210809,
     "sourceId": 114239,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 597.11667,
   "end_time": "2025-11-22T15:42:03.400936",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-22T15:32:06.284266",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
