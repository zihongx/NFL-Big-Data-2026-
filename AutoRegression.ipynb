{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c643db2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:19:41.411455Z",
     "iopub.status.busy": "2025-11-22T08:19:41.411210Z",
     "iopub.status.idle": "2025-11-22T08:19:49.257778Z",
     "shell.execute_reply": "2025-11-22T08:19:49.256884Z"
    },
    "papermill": {
     "duration": 7.853684,
     "end_time": "2025-11-22T08:19:49.259067",
     "exception": false,
     "start_time": "2025-11-22T08:19:41.405383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Step 0: Imports & Config\n",
    "# ======================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ceed8e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:19:49.268665Z",
     "iopub.status.busy": "2025-11-22T08:19:49.268280Z",
     "iopub.status.idle": "2025-11-22T08:19:53.777363Z",
     "shell.execute_reply": "2025-11-22T08:19:53.776301Z"
    },
    "papermill": {
     "duration": 4.515444,
     "end_time": "2025-11-22T08:19:53.778770",
     "exception": false,
     "start_time": "2025-11-22T08:19:49.263326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading week 01 ...\n",
      "Loading week 02 ...\n",
      "Loading week 03 ...\n",
      "Loading week 04 ...\n",
      "\n",
      "==== Step 1: 原始多周数据形状 ====\n",
      "input_df shape : (1144532, 24)\n",
      "output_df shape: (130495, 7)\n",
      "weeks in input_df : [1, 2, 3, 4]\n",
      "weeks in output_df: [1, 2, 3, 4]\n",
      "\n",
      "input_df columns: ['game_id', 'play_id', 'player_to_predict', 'nfl_id', 'frame_id', 'play_direction', 'absolute_yardline_number', 'player_name', 'player_height', 'player_weight', 'player_birth_date', 'player_position', 'player_side', 'player_role', 'x', 'y', 's', 'a', 'dir', 'o', 'num_frames_output', 'ball_land_x', 'ball_land_y', 'week']\n",
      "output_df columns: ['game_id', 'play_id', 'nfl_id', 'frame_id', 'x', 'y', 'week']\n",
      "\n",
      "input_df 示例行：\n",
      "      game_id  play_id  player_to_predict  nfl_id  frame_id play_direction  absolute_yardline_number player_name player_height  player_weight player_birth_date player_position player_side  \\\n",
      "0  2023090700      101              False   54527         1          right                        42  Bryan Cook           6-1            210        1999-09-07              FS     Defense   \n",
      "1  2023090700      101              False   54527         2          right                        42  Bryan Cook           6-1            210        1999-09-07              FS     Defense   \n",
      "2  2023090700      101              False   54527         3          right                        42  Bryan Cook           6-1            210        1999-09-07              FS     Defense   \n",
      "\n",
      "          player_role      x      y     s     a     dir       o  num_frames_output  ball_land_x  ball_land_y  week  \n",
      "0  Defensive Coverage  52.33  36.94  0.09  0.39  322.40  238.24                 21    63.259998        -0.22     1  \n",
      "1  Defensive Coverage  52.33  36.94  0.04  0.61  200.89  236.05                 21    63.259998        -0.22     1  \n",
      "2  Defensive Coverage  52.33  36.93  0.12  0.73  147.55  240.60                 21    63.259998        -0.22     1  \n",
      "\n",
      "output_df 示例行：\n",
      "      game_id  play_id  nfl_id  frame_id      x      y  week\n",
      "0  2023090700      101   46137         1  56.22  17.28     1\n",
      "1  2023090700      101   46137         2  56.63  16.88     1\n",
      "2  2023090700      101   46137         3  57.06  16.46     1\n",
      "\n",
      "play_direction 计数：\n",
      "play_direction\n",
      "right    601684\n",
      "left     542848\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Step 1: Load input/output data\n",
    "# ======================================\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 先用 1~4 周，跑顺了再扩展\n",
    "weeks = [f\"{w:02d}\" for w in range(1, 5)]   # [\"01\",\"02\",\"03\",\"04\"]\n",
    "\n",
    "input_list = []\n",
    "output_list = []\n",
    "\n",
    "for w in weeks:\n",
    "    in_path  = f\"/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w{w}.csv\"\n",
    "    out_path = f\"/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w{w}.csv\"\n",
    "    \n",
    "    print(f\"Loading week {w} ...\")\n",
    "    input_w  = pd.read_csv(in_path)\n",
    "    output_w = pd.read_csv(out_path)\n",
    "\n",
    "    # 可选：加 week 标记，方便以后分析\n",
    "    input_w[\"week\"]  = int(w)\n",
    "    output_w[\"week\"] = int(w)\n",
    "    \n",
    "    input_list.append(input_w)\n",
    "    output_list.append(output_w)\n",
    "\n",
    "input_df  = pd.concat(input_list,  ignore_index=True)\n",
    "output_df = pd.concat(output_list, ignore_index=True)\n",
    "\n",
    "print(\"\\n==== Step 1: 原始多周数据形状 ====\")\n",
    "print(\"input_df shape :\", input_df.shape)\n",
    "print(\"output_df shape:\", output_df.shape)\n",
    "print(\"weeks in input_df :\", sorted(input_df['week'].unique().tolist()))\n",
    "print(\"weeks in output_df:\", sorted(output_df['week'].unique().tolist()))\n",
    "\n",
    "print(\"\\ninput_df columns:\", list(input_df.columns))\n",
    "print(\"output_df columns:\", list(output_df.columns))\n",
    "\n",
    "print(\"\\ninput_df 示例行：\")\n",
    "print(input_df.head(3))\n",
    "\n",
    "print(\"\\noutput_df 示例行：\")\n",
    "print(output_df.head(3))\n",
    "\n",
    "print(\"\\nplay_direction 计数：\")\n",
    "print(input_df[\"play_direction\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ec7ea2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:19:53.789733Z",
     "iopub.status.busy": "2025-11-22T08:19:53.789465Z",
     "iopub.status.idle": "2025-11-22T08:19:54.001422Z",
     "shell.execute_reply": "2025-11-22T08:19:54.000524Z"
    },
    "papermill": {
     "duration": 0.219712,
     "end_time": "2025-11-22T08:19:54.002862",
     "exception": false,
     "start_time": "2025-11-22T08:19:53.783150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Step 2: 过滤 player_to_predict 后 ====\n",
      "input_df shape (filtered): (304184, 24)\n",
      "player_to_predict 统计:\n",
      "player_to_predict\n",
      "True    304184\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n==== Step 2: 过滤 player_to_predict 后 ====\")\n",
    "\n",
    "# 只保留需要预测的球员\n",
    "input_df = input_df[input_df[\"player_to_predict\"] == True].copy()\n",
    "\n",
    "print(\"input_df shape (filtered):\", input_df.shape)\n",
    "print(\"player_to_predict 统计:\")\n",
    "print(input_df[\"player_to_predict\"].value_counts())\n",
    "\n",
    "# 为了方便后面 join，确保类型一致\n",
    "key_cols = [\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"]\n",
    "output_df = output_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9067f5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:19:54.013436Z",
     "iopub.status.busy": "2025-11-22T08:19:54.013134Z",
     "iopub.status.idle": "2025-11-22T08:19:54.018498Z",
     "shell.execute_reply": "2025-11-22T08:19:54.017720Z"
    },
    "papermill": {
     "duration": 0.011868,
     "end_time": "2025-11-22T08:19:54.019604",
     "exception": false,
     "start_time": "2025-11-22T08:19:54.007736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mirror_xy(df, direction_col=\"play_direction\"):\n",
    "    df = df.copy()\n",
    "    is_left = df[direction_col] == \"left\"\n",
    "\n",
    "    # 1. x / y 一定要镜像（input / output 都有）\n",
    "    df.loc[is_left, \"x\"] = 120.0 - df.loc[is_left, \"x\"]\n",
    "    df.loc[is_left, \"y\"] = 53.3 - df.loc[is_left, \"y\"]\n",
    "\n",
    "    # 2. 如果有 dir，再镜像 dir\n",
    "    if \"dir\" in df.columns:\n",
    "        df.loc[is_left, \"dir\"] = (180.0 - df.loc[is_left, \"dir\"]) % 360\n",
    "\n",
    "    # 3. 如果有 o，再镜像 o\n",
    "    if \"o\" in df.columns:\n",
    "        df.loc[is_left, \"o\"] = (180.0 - df.loc[is_left, \"o\"]) % 360\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abf389d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:19:54.028779Z",
     "iopub.status.busy": "2025-11-22T08:19:54.028558Z",
     "iopub.status.idle": "2025-11-22T08:19:54.180023Z",
     "shell.execute_reply": "2025-11-22T08:19:54.178882Z"
    },
    "papermill": {
     "duration": 0.157833,
     "end_time": "2025-11-22T08:19:54.181409",
     "exception": false,
     "start_time": "2025-11-22T08:19:54.023576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Step 3: play_direction 映射检查 ====\n",
      "不同 play_direction 个数: 2\n",
      "play_direction\n",
      "right    1749\n",
      "left     1603\n",
      "Name: count, dtype: int64\n",
      "\n",
      "镜像前后对比 (input_df)：\n",
      "选取 game_id=2023090700, play_id=101 的前 5 行对比：\n",
      "\n",
      "原始：\n",
      "    frame_id play_direction      x      y     dir       o\n",
      "26         1          right  51.32  20.69   79.43  267.68\n",
      "27         2          right  51.35  20.66  118.07  268.66\n",
      "28         3          right  51.39  20.63  130.89  269.78\n",
      "29         4          right  51.43  20.61  134.50  269.78\n",
      "30         5          right  51.48  20.58  129.79  269.06\n",
      "\n",
      "归一化后：\n",
      "    frame_id play_direction      x      y     dir       o\n",
      "26         1          right  51.32  20.69   79.43  267.68\n",
      "27         2          right  51.35  20.66  118.07  268.66\n",
      "28         3          right  51.39  20.63  130.89  269.78\n",
      "29         4          right  51.43  20.61  134.50  269.78\n",
      "30         5          right  51.48  20.58  129.79  269.06\n",
      "\n",
      "output_df 中 play_direction 缺失个数: 0\n",
      "\n",
      "镜像后的 output_df_norm 示例:\n",
      "      game_id  play_id  nfl_id  frame_id      x      y  week play_direction\n",
      "0  2023090700      101   46137         1  56.22  17.28     1          right\n",
      "1  2023090700      101   46137         2  56.63  16.88     1          right\n",
      "2  2023090700      101   46137         3  57.06  16.46     1          right\n",
      "3  2023090700      101   46137         4  57.48  16.02     1          right\n",
      "4  2023090700      101   46137         5  57.91  15.56     1          right\n"
     ]
    }
   ],
   "source": [
    "# 3.1 为每个 play 建立 play_direction 映射\n",
    "play_dir_map = (\n",
    "    input_df[[\"game_id\", \"play_id\", \"play_direction\"]]\n",
    "    .drop_duplicates(subset=[\"game_id\", \"play_id\"])\n",
    "    .set_index([\"game_id\", \"play_id\"])[\"play_direction\"]\n",
    ")\n",
    "\n",
    "print(\"\\n==== Step 3: play_direction 映射检查 ====\")\n",
    "print(\"不同 play_direction 个数:\", play_dir_map.nunique())\n",
    "print(play_dir_map.value_counts())\n",
    "\n",
    "# 3.2 左右归一化函数（你已经定义过的 mirror_xy，直接用）\n",
    "input_df_norm = mirror_xy(input_df, \"play_direction\")\n",
    "\n",
    "print(\"\\n镜像前后对比 (input_df)：\")\n",
    "sample_keys = input_df_norm[[\"game_id\", \"play_id\"]].drop_duplicates().head(1).values[0]\n",
    "g, p = sample_keys\n",
    "print(f\"选取 game_id={g}, play_id={p} 的前 5 行对比：\\n\")\n",
    "\n",
    "print(\"原始：\")\n",
    "print(\n",
    "    input_df[(input_df.game_id==g) & (input_df.play_id==p)]\n",
    "    [[\"frame_id\",\"play_direction\",\"x\",\"y\",\"dir\",\"o\"]].head()\n",
    ")\n",
    "print(\"\\n归一化后：\")\n",
    "print(\n",
    "    input_df_norm[(input_df_norm.game_id==g) & (input_df_norm.play_id==p)]\n",
    "    [[\"frame_id\",\"play_direction\",\"x\",\"y\",\"dir\",\"o\"]].head()\n",
    ")\n",
    "\n",
    "# 3.3 给 output 补上 play_direction 并做同样的镜像\n",
    "output_df_norm = output_df.merge(\n",
    "    play_dir_map.rename(\"play_direction\"),\n",
    "    on=[\"game_id\", \"play_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "missing_dir = output_df_norm[\"play_direction\"].isna().sum()\n",
    "print(\"\\noutput_df 中 play_direction 缺失个数:\", missing_dir)\n",
    "\n",
    "output_df_norm = mirror_xy(output_df_norm, \"play_direction\")\n",
    "\n",
    "print(\"\\n镜像后的 output_df_norm 示例:\")\n",
    "print(output_df_norm.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef99270",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:19:54.191269Z",
     "iopub.status.busy": "2025-11-22T08:19:54.191028Z",
     "iopub.status.idle": "2025-11-22T08:19:54.214230Z",
     "shell.execute_reply": "2025-11-22T08:19:54.213389Z"
    },
    "papermill": {
     "duration": 0.029563,
     "end_time": "2025-11-22T08:19:54.215500",
     "exception": false,
     "start_time": "2025-11-22T08:19:54.185937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_cols: ['x', 'y', 's', 'a', 'dir', 'o', 'ball_land_x', 'ball_land_y']\n",
      "\n",
      "input_df_norm 中这些列的前几行：\n",
      "       game_id  play_id  nfl_id  frame_id      x      y     s     a     dir       o  ball_land_x  ball_land_y\n",
      "26  2023090700      101   46137         1  51.32  20.69  0.31  0.49   79.43  267.68    63.259998        -0.22\n",
      "27  2023090700      101   46137         2  51.35  20.66  0.36  0.74  118.07  268.66    63.259998        -0.22\n",
      "28  2023090700      101   46137         3  51.39  20.63  0.44  0.76  130.89  269.78    63.259998        -0.22\n",
      "29  2023090700      101   46137         4  51.43  20.61  0.48  0.62  134.50  269.78    63.259998        -0.22\n",
      "30  2023090700      101   46137         5  51.48  20.58  0.54  0.44  129.79  269.06    63.259998        -0.22\n",
      "\n",
      "input_df_norm 是否有 NaN:\n",
      "x    0\n",
      "y    0\n",
      "dtype: int64\n",
      "\n",
      "output_df_norm 是否有 NaN:\n",
      "x    0\n",
      "y    0\n",
      "dtype: int64\n",
      "\n",
      "input x/y 范围: 6.45 119.27 0.6899999999999977 52.58\n",
      "output x/y 范围: 11.89 120.83 0.3200000000000003 53.72\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\"x\", \"y\", \"s\", \"a\", \"dir\", \"o\", \"ball_land_x\", \"ball_land_y\"]\n",
    "print(\"\\nfeature_cols:\", feature_cols)\n",
    "\n",
    "print(\"\\ninput_df_norm 中这些列的前几行：\")\n",
    "print(input_df_norm[[\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"] + feature_cols].head())\n",
    "\n",
    "# 检查 NaN / 范围\n",
    "print(\"\\ninput_df_norm 是否有 NaN:\")\n",
    "print(input_df_norm[[\"x\", \"y\"]].isna().sum())\n",
    "\n",
    "print(\"\\noutput_df_norm 是否有 NaN:\")\n",
    "print(output_df_norm[[\"x\", \"y\"]].isna().sum())\n",
    "\n",
    "print(\"\\ninput x/y 范围:\",\n",
    "      input_df_norm[\"x\"].min(), input_df_norm[\"x\"].max(),\n",
    "      input_df_norm[\"y\"].min(), input_df_norm[\"y\"].max())\n",
    "\n",
    "print(\"output x/y 范围:\",\n",
    "      output_df_norm[\"x\"].min(), output_df_norm[\"x\"].max(),\n",
    "      output_df_norm[\"y\"].min(), output_df_norm[\"y\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "964f8efa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:19:54.226035Z",
     "iopub.status.busy": "2025-11-22T08:19:54.225833Z",
     "iopub.status.idle": "2025-11-22T08:19:54.236952Z",
     "shell.execute_reply": "2025-11-22T08:19:54.236456Z"
    },
    "papermill": {
     "duration": 0.017578,
     "end_time": "2025-11-22T08:19:54.238041",
     "exception": false,
     "start_time": "2025-11-22T08:19:54.220463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_sequences_with_mask(input_df, output_df, feature_cols, T_in=32, T_out=21):\n",
    "\n",
    "    print(\"\\n==== Step 4: build_sequences (with mask) ====\")\n",
    "\n",
    "    X_list, Y_list, M_list = [], [], []\n",
    "    keys = []\n",
    "\n",
    "    grouped_in  = input_df.groupby([\"game_id\", \"play_id\", \"nfl_id\"])\n",
    "    grouped_out = output_df.groupby([\"game_id\", \"play_id\", \"nfl_id\"])\n",
    "\n",
    "    len_out_counter = {}\n",
    "    dropped_no_output = 0\n",
    "\n",
    "#    total_keys = 0\n",
    "\n",
    "    for key, g_in in grouped_in:\n",
    "        if key not in grouped_out.groups:\n",
    "            continue\n",
    "        g_out = grouped_out.get_group(key)\n",
    "        \n",
    "#        total_keys += 1\n",
    "\n",
    "        # 按 frame_id 排序，保证时间顺序\n",
    "        g_in = g_in.sort_values(\"frame_id\")\n",
    "        g_out = g_out.sort_values(\"frame_id\")\n",
    "\n",
    "        # --- 构造 X 序列 ---\n",
    "        x_feat = g_in[feature_cols].to_numpy(dtype=\"float32\")  # [L_in, F]\n",
    "        L_in, F = x_feat.shape\n",
    "\n",
    "        if L_in >= T_in:\n",
    "            X_seq = x_feat[-T_in:]  # 取最后 T_in 帧\n",
    "        else:\n",
    "            pad_len = T_in - L_in\n",
    "            pad = np.zeros((pad_len, F), dtype=\"float32\")\n",
    "            X_seq = np.concatenate([pad, x_feat], axis=0)\n",
    "\n",
    "        # --- 构造 Y 序列 & mask ---\n",
    "        out_xy = g_out[[\"x\", \"y\"]].to_numpy(dtype=\"float32\")   # [L_out, 2]\n",
    "        L_out = out_xy.shape[0]\n",
    "\n",
    "        len_out_counter[L_out] = len_out_counter.get(L_out, 0) + 1\n",
    "\n",
    "        # 没有任何输出，跳过\n",
    "        if L_out == 0:\n",
    "            dropped_no_output += 1\n",
    "            continue\n",
    "\n",
    "        if L_out >= T_out:\n",
    "            Y_seq = out_xy[:T_out]\n",
    "            mask = np.ones(T_out, dtype=\"float32\")\n",
    "        else:\n",
    "            # 用最后一帧的位置重复填充\n",
    "            last_xy = out_xy[-1]\n",
    "            pad_len = T_out - L_out\n",
    "            pad_xy = np.repeat(last_xy[None, :], pad_len, axis=0)  # [pad_len, 2]\n",
    "            Y_seq = np.concatenate([out_xy, pad_xy], axis=0)\n",
    "\n",
    "            mask = np.concatenate([\n",
    "                np.ones(L_out, dtype=\"float32\"),\n",
    "                np.zeros(pad_len, dtype=\"float32\"),\n",
    "            ], axis=0)  # [T_out]\n",
    "\n",
    "        X_list.append(X_seq)\n",
    "        Y_list.append(Y_seq)\n",
    "        M_list.append(mask)\n",
    "        keys.append(key)\n",
    "\n",
    "    # 堆叠成 ndarray\n",
    "    X_all = np.stack(X_list, axis=0)\n",
    "    Y_all = np.stack(Y_list, axis=0)\n",
    "    M_all = np.stack(M_list, axis=0)\n",
    "\n",
    "    print(\"共有样本 key 数:\", len(keys))\n",
    "    print(\"build_sequences 完成:\")\n",
    "    print(\"X_all shape:\", X_all.shape)  # 期望 [N, T_in, F]\n",
    "    print(\"Y_all shape:\", Y_all.shape)  # 期望 [N, T_out, 2]\n",
    "    print(\"M_all shape:\", M_all.shape)  # 期望 [N, T_out]\")\n",
    "\n",
    "    print(\"\\n被丢弃的样本（L_out == 0）数量:\", dropped_no_output)\n",
    "\n",
    "    print(\"\\n输出长度分布 (原始 L_out):\")\n",
    "    for L_out in sorted(len_out_counter.keys()):\n",
    "        print(f\"  len_out = {L_out}: {len_out_counter[L_out]} 条\")\n",
    "\n",
    "    # 打印一个样本看一下\n",
    "    if X_all.shape[0] > 0:\n",
    "        print(\"\\n示例样本 0:\")\n",
    "        print(\"X_all[0] 前 3 帧:\\n\", X_all[0, :3])\n",
    "        print(\"Y_all[0] 前 3 帧:\\n\", Y_all[0, :3])\n",
    "        print(\"M_all[0]:\\n\", M_all[0])\n",
    "\n",
    "    return X_all, Y_all, M_all, keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97a4d458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:19:54.248467Z",
     "iopub.status.busy": "2025-11-22T08:19:54.247890Z",
     "iopub.status.idle": "2025-11-22T08:20:06.963272Z",
     "shell.execute_reply": "2025-11-22T08:20:06.962475Z"
    },
    "papermill": {
     "duration": 12.721971,
     "end_time": "2025-11-22T08:20:06.964663",
     "exception": false,
     "start_time": "2025-11-22T08:19:54.242692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Step 4: build_sequences (with mask) ====\n",
      "共有样本 key 数: 10913\n",
      "build_sequences 完成:\n",
      "X_all shape: (10913, 32, 8)\n",
      "Y_all shape: (10913, 21, 2)\n",
      "M_all shape: (10913, 21)\n",
      "\n",
      "被丢弃的样本（L_out == 0）数量: 0\n",
      "\n",
      "输出长度分布 (原始 L_out):\n",
      "  len_out = 5: 61 条\n",
      "  len_out = 6: 391 条\n",
      "  len_out = 7: 1152 条\n",
      "  len_out = 8: 1450 条\n",
      "  len_out = 9: 1389 条\n",
      "  len_out = 10: 1319 条\n",
      "  len_out = 11: 906 条\n",
      "  len_out = 12: 815 条\n",
      "  len_out = 13: 586 条\n",
      "  len_out = 14: 464 条\n",
      "  len_out = 15: 357 条\n",
      "  len_out = 16: 284 条\n",
      "  len_out = 17: 249 条\n",
      "  len_out = 18: 204 条\n",
      "  len_out = 19: 197 条\n",
      "  len_out = 20: 143 条\n",
      "  len_out = 21: 102 条\n",
      "  len_out = 22: 125 条\n",
      "  len_out = 23: 166 条\n",
      "  len_out = 24: 110 条\n",
      "  len_out = 25: 68 条\n",
      "  len_out = 26: 111 条\n",
      "  len_out = 27: 67 条\n",
      "  len_out = 28: 58 条\n",
      "  len_out = 29: 39 条\n",
      "  len_out = 30: 38 条\n",
      "  len_out = 31: 11 条\n",
      "  len_out = 32: 10 条\n",
      "  len_out = 33: 3 条\n",
      "  len_out = 34: 19 条\n",
      "  len_out = 36: 4 条\n",
      "  len_out = 40: 7 条\n",
      "  len_out = 94: 8 条\n",
      "\n",
      "示例样本 0:\n",
      "X_all[0] 前 3 帧:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Y_all[0] 前 3 帧:\n",
      " [[53.2  13.98]\n",
      " [53.96 13.78]\n",
      " [54.7  13.54]]\n",
      "M_all[0]:\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "==== Step 4: build_sequences ====\n",
      "共有样本 key 数: 10913\n",
      "X_all shape: (10913, 32, 8)\n",
      "Y_all shape: (10913, 21, 2)\n",
      "M_all Shape: (10913, 21)\n"
     ]
    }
   ],
   "source": [
    "T_in  = 32\n",
    "T_out = 21\n",
    "\n",
    "X_all, Y_all, M_all, keys = build_sequences_with_mask(\n",
    "    input_df_norm,\n",
    "    output_df_norm,\n",
    "    feature_cols,\n",
    "    T_in=T_in,\n",
    "    T_out=T_out,\n",
    ")\n",
    "print(\"\\n==== Step 4: build_sequences ====\")\n",
    "print(\"共有样本 key 数:\", len(X_all))\n",
    "print(\"X_all shape:\", X_all.shape)  # 期望 (N, 32, F)\n",
    "print(\"Y_all shape:\", Y_all.shape)  # 期望 (N, 21, 2)\n",
    "print(\"M_all Shape:\",  M_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1338892a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:20:06.975721Z",
     "iopub.status.busy": "2025-11-22T08:20:06.975491Z",
     "iopub.status.idle": "2025-11-22T08:20:06.991519Z",
     "shell.execute_reply": "2025-11-22T08:20:06.990846Z"
    },
    "papermill": {
     "duration": 0.022476,
     "end_time": "2025-11-22T08:20:06.992604",
     "exception": false,
     "start_time": "2025-11-22T08:20:06.970128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 8730\n",
      "Val   size: 2183\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = len(keys)\n",
    "keys = np.array(keys)\n",
    "\n",
    "# 随机打乱索引\n",
    "rng = np.random.default_rng(42)\n",
    "perm = rng.permutation(N)\n",
    "\n",
    "split = int(N * 0.8)   # 80% 训练，20% 验证\n",
    "train_idx = perm[:split]\n",
    "val_idx   = perm[split:]\n",
    "\n",
    "X_train, Y_train, M_train = X_all[train_idx], Y_all[train_idx], M_all[train_idx]\n",
    "X_val,   Y_val,   M_val   = X_all[val_idx],   Y_all[val_idx],   M_all[val_idx]\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0])\n",
    "print(\"Val   size:\", X_val.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c629db45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:20:07.003040Z",
     "iopub.status.busy": "2025-11-22T08:20:07.002450Z",
     "iopub.status.idle": "2025-11-22T08:20:07.008025Z",
     "shell.execute_reply": "2025-11-22T08:20:07.007444Z"
    },
    "papermill": {
     "duration": 0.011892,
     "end_time": "2025-11-22T08:20:07.009017",
     "exception": false,
     "start_time": "2025-11-22T08:20:06.997125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y, M):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.M = M\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.from_numpy(self.X[idx]).float(),\n",
    "            torch.from_numpy(self.Y[idx]).float(),\n",
    "            torch.from_numpy(self.M[idx]).float(),\n",
    "        )\n",
    "\n",
    "def build_loader(X, Y, M, batch_size=64, shuffle=True):\n",
    "    dataset = Seq2SeqDataset(X, Y, M)\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # 检查一批\n",
    "    for i, (xb, yb, mb) in enumerate(loader):\n",
    "        print(\"First batch idx:\", i)\n",
    "        print(\" xb shape:\", xb.shape)  # [B, 32, F]\n",
    "        print(\" yb shape:\", yb.shape)  # [B, 21, 2]\n",
    "        print(\" mb shape:\", mb.shape)  # [B, 21]\n",
    "        break\n",
    "\n",
    "    return loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1827b59c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:20:07.018858Z",
     "iopub.status.busy": "2025-11-22T08:20:07.018673Z",
     "iopub.status.idle": "2025-11-22T08:20:07.070875Z",
     "shell.execute_reply": "2025-11-22T08:20:07.070043Z"
    },
    "papermill": {
     "duration": 0.058566,
     "end_time": "2025-11-22T08:20:07.072011",
     "exception": false,
     "start_time": "2025-11-22T08:20:07.013445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch idx: 0\n",
      " xb shape: torch.Size([64, 32, 8])\n",
      " yb shape: torch.Size([64, 21, 2])\n",
      " mb shape: torch.Size([64, 21])\n",
      "First batch idx: 0\n",
      " xb shape: torch.Size([64, 32, 8])\n",
      " yb shape: torch.Size([64, 21, 2])\n",
      " mb shape: torch.Size([64, 21])\n"
     ]
    }
   ],
   "source": [
    "train_loader = build_loader(X_train, Y_train, M_train, batch_size=64, shuffle=True)\n",
    "val_loader   = build_loader(X_val,   Y_val,   M_val,   batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7218b86c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:20:07.082490Z",
     "iopub.status.busy": "2025-11-22T08:20:07.081913Z",
     "iopub.status.idle": "2025-11-22T08:20:07.094771Z",
     "shell.execute_reply": "2025-11-22T08:20:07.094209Z"
    },
    "papermill": {
     "duration": 0.019074,
     "end_time": "2025-11-22T08:20:07.095730",
     "exception": false,
     "start_time": "2025-11-22T08:20:07.076656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# =========================\n",
    "# Positional Encoding\n",
    "# =========================\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 64):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2, dtype=torch.float32)\n",
    "            * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # [1, max_len, d_model]\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [B, T, d_model]\n",
    "        T = x.size(1)\n",
    "        return x + self.pe[:, :T, :]\n",
    "        \n",
    "\n",
    "# =========================\n",
    "# 自回归 Transformer 模型\n",
    "# 输入: [B, T_in, F]\n",
    "# 输出: [B, T_out, 2]  (未来每一帧的 x,y)\n",
    "# =========================\n",
    "class AutoRegressiveTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        d_model: int = 128,\n",
    "        nhead: int = 4,\n",
    "        num_layers: int = 3,\n",
    "        T_in: int = 32,\n",
    "        T_out: int = 21,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.T_out = T_out\n",
    "\n",
    "        # 编码器：把输入特征映射到 d_model\n",
    "        self.input_fc = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len=T_in + T_out)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=4 * d_model,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "\n",
    "        # 解码器：一步步用“上一时刻位置”生成下一时刻位置\n",
    "        dec_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=4 * d_model,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(dec_layer, num_layers=num_layers)\n",
    "\n",
    "        # 把上一步的 (x,y) 位置映射到 d_model 作为 decoder 输入\n",
    "        self.query_fc = nn.Linear(2, d_model)\n",
    "\n",
    "        # 输出层：d_model -> (x,y)\n",
    "        self.out_fc = nn.Linear(d_model, 2)\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, size: int, device):\n",
    "        # 上三角为 -inf 的注意力 mask，保证自回归\n",
    "        mask = torch.triu(\n",
    "            torch.full((size, size), float(\"-inf\"), device=device), diagonal=1\n",
    "        )\n",
    "        return mask\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src: torch.Tensor,           # [B, T_in, F]\n",
    "        target: torch.Tensor = None, # [B, T_out, 2]  (训练时可选)\n",
    "        teacher_forcing_ratio: float = 0.0,\n",
    "    ) -> torch.Tensor:\n",
    "        B, T_in, _ = src.shape\n",
    "        device = src.device\n",
    "\n",
    "        # ===== 编码器 =====\n",
    "        src_embed = self.input_fc(src)          # [B, T_in, d_model]\n",
    "        src_embed = self.pos_encoder(src_embed)\n",
    "        memory = self.encoder(src_embed)        # [B, T_in, d_model]\n",
    "\n",
    "        # 最后一帧已观测位置 (注意：feature_cols 的前两列是 x,y)\n",
    "        last_pos = src[:, -1, :2]               # [B, 2]\n",
    "\n",
    "        outputs = []\n",
    "        dec_inputs = []\n",
    "\n",
    "        for t in range(self.T_out):\n",
    "            # 决定当前步使用什么“上一位置”作为输入\n",
    "            if t == 0:\n",
    "                prev_pos = last_pos             # 第一步：用观测的最后一帧位置\n",
    "            else:\n",
    "                use_teacher = (\n",
    "                    (target is not None)\n",
    "                    and (teacher_forcing_ratio > 0)\n",
    "                    and (torch.rand(1).item() < teacher_forcing_ratio)\n",
    "                )\n",
    "                if use_teacher:\n",
    "                    # Teacher Forcing：用真值的上一步位置\n",
    "                    prev_pos = target[:, t - 1, :]   # [B, 2]\n",
    "                else:\n",
    "                    # 自回归：用模型预测的上一帧\n",
    "                    prev_pos = outputs[-1]          # [B, 2]\n",
    "\n",
    "            dec_inputs.append(prev_pos.unsqueeze(1))   # [B, 1, 2]\n",
    "            dec_seq = torch.cat(dec_inputs, dim=1)     # [B, t+1, 2]\n",
    "\n",
    "            dec_embed = self.query_fc(dec_seq)         # [B, t+1, d_model]\n",
    "            dec_embed = self.pos_encoder(dec_embed)\n",
    "\n",
    "            tgt_mask = self._generate_square_subsequent_mask(\n",
    "                dec_embed.size(1), device\n",
    "            )\n",
    "\n",
    "            dec_out = self.decoder(\n",
    "                dec_embed, memory, tgt_mask=tgt_mask\n",
    "            )                                          # [B, t+1, d_model]\n",
    "\n",
    "            step_out = self.out_fc(dec_out[:, -1, :])  # 只取最后一帧 [B, 2]\n",
    "            outputs.append(step_out)\n",
    "\n",
    "        outputs = torch.stack(outputs, dim=1)          # [B, T_out, 2]\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e1b427f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:20:07.105218Z",
     "iopub.status.busy": "2025-11-22T08:20:07.104996Z",
     "iopub.status.idle": "2025-11-22T08:20:11.937048Z",
     "shell.execute_reply": "2025-11-22T08:20:11.936467Z"
    },
    "papermill": {
     "duration": 4.838383,
     "end_time": "2025-11-22T08:20:11.938389",
     "exception": false,
     "start_time": "2025-11-22T08:20:07.100006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "input_dim = X_all.shape[-1]      # 8\n",
    "d_model   = 128\n",
    "\n",
    "model = AutoRegressiveTransformer(\n",
    "    input_dim=input_dim,\n",
    "    d_model=d_model,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46ca9f33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:20:11.949126Z",
     "iopub.status.busy": "2025-11-22T08:20:11.948409Z",
     "iopub.status.idle": "2025-11-22T08:20:11.954320Z",
     "shell.execute_reply": "2025-11-22T08:20:11.953725Z"
    },
    "papermill": {
     "duration": 0.012378,
     "end_time": "2025-11-22T08:20:11.955453",
     "exception": false,
     "start_time": "2025-11-22T08:20:11.943075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, clip_grad=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "\n",
    "    for Xb, Yb, Mb in loader:\n",
    "        Xb = Xb.to(device)          # [B, 32, F]\n",
    "        Yb = Yb.to(device)          # [B, 21, 2]\n",
    "        Mb = Mb.to(device)          # [B, 21]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 最后一帧观测位置\n",
    "        last_pos = Xb[:, -1, :2]    # [B, 2]\n",
    "\n",
    "        # 预测相对位移\n",
    "        preds_rel = model(Xb)       # [B, 21, 2]\n",
    "        preds_abs = preds_rel + last_pos.unsqueeze(1)\n",
    "\n",
    "        # 只在有效帧上算 MSE\n",
    "        diff = preds_abs - Yb                    # [B, 21, 2]\n",
    "        diff = diff * Mb.unsqueeze(-1)           # mask 掉 padding\n",
    "        se = (diff ** 2).sum()                   # 总平方误差\n",
    "        cnt = Mb.sum() * 2.0                     # 有效坐标个数 (x,y)\n",
    "\n",
    "        loss = se / cnt\n",
    "        loss.backward()\n",
    "\n",
    "        if clip_grad is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_count += 1\n",
    "\n",
    "    return total_loss / max(total_count, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ea9a9aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:20:11.965863Z",
     "iopub.status.busy": "2025-11-22T08:20:11.965370Z",
     "iopub.status.idle": "2025-11-22T08:20:11.970786Z",
     "shell.execute_reply": "2025-11-22T08:20:11.970096Z"
    },
    "papermill": {
     "duration": 0.011464,
     "end_time": "2025-11-22T08:20:11.971869",
     "exception": false,
     "start_time": "2025-11-22T08:20:11.960405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_rmse_on_loader(model, loader):\n",
    "    model.eval()\n",
    "    se_sum = 0.0\n",
    "    n = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for Xb, Yb, Mb in loader:\n",
    "            Xb = Xb.to(device)\n",
    "            Yb = Yb.to(device)\n",
    "            Mb = Mb.to(device)\n",
    "\n",
    "            last_pos = Xb[:, -1, :2]\n",
    "            preds_rel = model(Xb)\n",
    "            preds_abs = preds_rel + last_pos.unsqueeze(1)\n",
    "\n",
    "            diff = preds_abs - Yb           # [B, 21, 2]\n",
    "            diff = diff * Mb.unsqueeze(-1)  # 只算有效帧\n",
    "\n",
    "            dist2 = diff[..., 0]**2 + diff[..., 1]**2   # [B, 21]\n",
    "            se_sum += dist2.sum().item()\n",
    "            n += Mb.sum().item()\n",
    "\n",
    "    rmse = math.sqrt(se_sum / max(n, 1.0))\n",
    "    print(f\"RMSE on this loader (yards): {rmse:.4f}\")\n",
    "    model.train()\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11771cbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:20:11.981971Z",
     "iopub.status.busy": "2025-11-22T08:20:11.981579Z",
     "iopub.status.idle": "2025-11-22T08:32:09.788134Z",
     "shell.execute_reply": "2025-11-22T08:32:09.787222Z"
    },
    "papermill": {
     "duration": 717.812981,
     "end_time": "2025-11-22T08:32:09.789357",
     "exception": false,
     "start_time": "2025-11-22T08:20:11.976376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss = 8.3137\n",
      "RMSE on this loader (yards): 3.6845\n",
      "           Val RMSE   = 3.6845\n",
      "  ✅ New best model saved. RMSE = 3.6845\n",
      "Epoch 2/20 | Train Loss = 6.7108\n",
      "RMSE on this loader (yards): 3.4918\n",
      "           Val RMSE   = 3.4918\n",
      "  ✅ New best model saved. RMSE = 3.4918\n",
      "Epoch 3/20 | Train Loss = 6.0570\n",
      "RMSE on this loader (yards): 3.3270\n",
      "           Val RMSE   = 3.3270\n",
      "  ✅ New best model saved. RMSE = 3.3270\n",
      "Epoch 4/20 | Train Loss = 5.7462\n",
      "RMSE on this loader (yards): 3.3317\n",
      "           Val RMSE   = 3.3317\n",
      "Epoch 5/20 | Train Loss = 5.3336\n",
      "RMSE on this loader (yards): 3.1859\n",
      "           Val RMSE   = 3.1859\n",
      "  ✅ New best model saved. RMSE = 3.1859\n",
      "Epoch 6/20 | Train Loss = 5.1683\n",
      "RMSE on this loader (yards): 3.1171\n",
      "           Val RMSE   = 3.1171\n",
      "  ✅ New best model saved. RMSE = 3.1171\n",
      "Epoch 7/20 | Train Loss = 4.8842\n",
      "RMSE on this loader (yards): 3.0770\n",
      "           Val RMSE   = 3.0770\n",
      "  ✅ New best model saved. RMSE = 3.0770\n",
      "Epoch 8/20 | Train Loss = 4.6330\n",
      "RMSE on this loader (yards): 2.9668\n",
      "           Val RMSE   = 2.9668\n",
      "  ✅ New best model saved. RMSE = 2.9668\n",
      "Epoch 9/20 | Train Loss = 4.4661\n",
      "RMSE on this loader (yards): 2.9706\n",
      "           Val RMSE   = 2.9706\n",
      "Epoch 10/20 | Train Loss = 4.3248\n",
      "RMSE on this loader (yards): 2.8666\n",
      "           Val RMSE   = 2.8666\n",
      "  ✅ New best model saved. RMSE = 2.8666\n",
      "Epoch 11/20 | Train Loss = 4.0636\n",
      "RMSE on this loader (yards): 2.8512\n",
      "           Val RMSE   = 2.8512\n",
      "  ✅ New best model saved. RMSE = 2.8512\n",
      "Epoch 12/20 | Train Loss = 4.0459\n",
      "RMSE on this loader (yards): 2.8187\n",
      "           Val RMSE   = 2.8187\n",
      "  ✅ New best model saved. RMSE = 2.8187\n",
      "Epoch 13/20 | Train Loss = 3.8296\n",
      "RMSE on this loader (yards): 2.8253\n",
      "           Val RMSE   = 2.8253\n",
      "Epoch 14/20 | Train Loss = 3.7507\n",
      "RMSE on this loader (yards): 2.7862\n",
      "           Val RMSE   = 2.7862\n",
      "  ✅ New best model saved. RMSE = 2.7862\n",
      "Epoch 15/20 | Train Loss = 3.5840\n",
      "RMSE on this loader (yards): 2.6048\n",
      "           Val RMSE   = 2.6048\n",
      "  ✅ New best model saved. RMSE = 2.6048\n",
      "Epoch 16/20 | Train Loss = 3.4956\n",
      "RMSE on this loader (yards): 2.6516\n",
      "           Val RMSE   = 2.6516\n",
      "Epoch 17/20 | Train Loss = 3.3917\n",
      "RMSE on this loader (yards): 2.5590\n",
      "           Val RMSE   = 2.5590\n",
      "  ✅ New best model saved. RMSE = 2.5590\n",
      "Epoch 18/20 | Train Loss = 3.3486\n",
      "RMSE on this loader (yards): 2.7011\n",
      "           Val RMSE   = 2.7011\n",
      "Epoch 19/20 | Train Loss = 3.4037\n",
      "RMSE on this loader (yards): 2.5428\n",
      "           Val RMSE   = 2.5428\n",
      "  ✅ New best model saved. RMSE = 2.5428\n",
      "Epoch 20/20 | Train Loss = 3.2558\n",
      "RMSE on this loader (yards): 2.5560\n",
      "           Val RMSE   = 2.5560\n",
      "\n",
      "Loaded best model with RMSE = 2.5428\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=20, clip_grad=1.0):\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, clip_grad)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} | Train Loss = {train_loss:.4f}\")\n",
    "\n",
    "        val_rmse = compute_rmse_on_loader(model, val_loader)\n",
    "        print(f\"           Val RMSE   = {val_rmse:.4f}\")\n",
    "\n",
    "        if val_rmse < best_rmse:\n",
    "            best_rmse = val_rmse\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_state, \"/kaggle/working/model_autoreg_best.pt\")\n",
    "            print(f\"  ✅ New best model saved. RMSE = {best_rmse:.4f}\")\n",
    "\n",
    "    # 训练结束后，加载最佳权重\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "        print(f\"\\nLoaded best model with RMSE = {best_rmse:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# 真正开始训练\n",
    "model = train_model(model, train_loader, val_loader, epochs=20, clip_grad=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85795f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:32:09.802980Z",
     "iopub.status.busy": "2025-11-22T08:32:09.802780Z",
     "iopub.status.idle": "2025-11-22T08:32:09.813462Z",
     "shell.execute_reply": "2025-11-22T08:32:09.812882Z"
    },
    "papermill": {
     "duration": 0.018875,
     "end_time": "2025-11-22T08:32:09.814513",
     "exception": false,
     "start_time": "2025-11-22T08:32:09.795638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "########\n",
    "## For Prediction\n",
    "########\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "T_IN  = 32\n",
    "T_OUT = 21\n",
    "\n",
    "FEATURE_COLS = [\"x\", \"y\", \"s\", \"a\", \"dir\", \"o\", \"ball_land_x\", \"ball_land_y\"]\n",
    "MODEL_PATH   = \"/kaggle/working/model_autoreg_best.pt\"   # 和训练时保持一致\n",
    "\n",
    "\n",
    "def mirror_xy(df: pd.DataFrame, direction_col: str = \"play_direction\") -> pd.DataFrame:\n",
    "    \"\"\"把所有 left 进攻的路线镜像成 right（和训练时完全一致）\"\"\"\n",
    "    df = df.copy()\n",
    "    is_left = df[direction_col] == \"left\"\n",
    "\n",
    "    df.loc[is_left, \"x\"]   = 120.0 - df.loc[is_left, \"x\"]\n",
    "    df.loc[is_left, \"y\"]   = 53.3  - df.loc[is_left, \"y\"]\n",
    "    df.loc[is_left, \"dir\"] = (180.0 - df.loc[is_left, \"dir\"]) % 360.0\n",
    "    df.loc[is_left, \"o\"]   = (180.0 - df.loc[is_left, \"o\"])   % 360.0\n",
    "    return df\n",
    "\n",
    "\n",
    "def unmirror_xy_xy_array(xy: np.ndarray, is_left: bool) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    把预测结果从“全是向右进攻的坐标系”翻回原始坐标系。\n",
    "    xy: [T, 2]\n",
    "    \"\"\"\n",
    "    if not is_left:\n",
    "        return xy\n",
    "\n",
    "    out = xy.copy()\n",
    "    out[:, 0] = 120.0 - out[:, 0]\n",
    "    out[:, 1] = 53.3  - out[:, 1]\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_test_sequences(input_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    根据 test_input 构造模型需要的输入序列。\n",
    "    返回：\n",
    "        X_all:  np.ndarray [N, T_IN, F]\n",
    "        keys:  list[(game_id, play_id, nfl_id)]\n",
    "        is_left: np.ndarray [N] 对应这个 play 是否原本向左\n",
    "    \"\"\"\n",
    "\n",
    "    # 只保留要预测的球员\n",
    "    df = input_df[input_df[\"player_to_predict\"] == True].copy()\n",
    "\n",
    "    # 记录每个 (game_id, play_id) 的原始进攻方向（left/right）\n",
    "    play_dir_map = (\n",
    "        df[[\"game_id\", \"play_id\", \"play_direction\"]]\n",
    "        .drop_duplicates(subset=[\"game_id\", \"play_id\"])\n",
    "        .set_index([\"game_id\", \"play_id\"])[\"play_direction\"]\n",
    "    )\n",
    "\n",
    "    # 做镜像（训练里对 input 做过）\n",
    "    df_norm = mirror_xy(df, \"play_direction\")\n",
    "\n",
    "    X_list   = []\n",
    "    keys     = []\n",
    "    is_lefts = []\n",
    "\n",
    "    for (g, p, n), group in df_norm.groupby([\"game_id\", \"play_id\", \"nfl_id\"]):\n",
    "        group = group.sort_values(\"frame_id\")\n",
    "        hist = group[FEATURE_COLS].to_numpy(dtype=np.float32)\n",
    "        L, F = hist.shape\n",
    "\n",
    "        # 如果帧数不足 T_IN，前面补零；否则取最后 T_IN 帧\n",
    "        if L >= T_IN:\n",
    "            hist = hist[-T_IN:]\n",
    "        else:\n",
    "            pad = np.zeros((T_IN - L, F), dtype=np.float32)\n",
    "            hist = np.concatenate([pad, hist], axis=0)\n",
    "\n",
    "        X_list.append(hist)\n",
    "        keys.append((g, p, n))\n",
    "        is_lefts.append(play_dir_map.loc[(g, p)] == \"left\")\n",
    "\n",
    "    X_all   = np.stack(X_list, axis=0)               # [N, T_IN, F]\n",
    "    is_left = np.array(is_lefts, dtype=bool)         # [N]\n",
    "\n",
    "    return X_all, keys, is_left\n",
    "\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    \"\"\"只用 X 的简单 Dataset，用在 DataLoader 里做 batch 推理。\"\"\"\n",
    "    def __init__(self, X_all: np.ndarray):\n",
    "        self.X = torch.from_numpy(X_all).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3ea5d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:32:09.827408Z",
     "iopub.status.busy": "2025-11-22T08:32:09.826869Z",
     "iopub.status.idle": "2025-11-22T08:32:09.833608Z",
     "shell.execute_reply": "2025-11-22T08:32:09.833005Z"
    },
    "papermill": {
     "duration": 0.014234,
     "end_time": "2025-11-22T08:32:09.834643",
     "exception": false,
     "start_time": "2025-11-22T08:32:09.820409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 和训练时保持一致\n",
    "T_in = 32\n",
    "T_out = 21\n",
    "feature_cols = ['x', 'y', 's', 'a', 'dir', 'o', 'ball_land_x', 'ball_land_y']\n",
    "\n",
    "def build_test_sequences(input_df_norm, feature_cols, T_in=32, T_out=21):\n",
    "    \"\"\"\n",
    "    只根据归一化后的 input_df_norm 构造:\n",
    "    - X_all: [N, T_in, F]\n",
    "    - last_pos: [N, 2] 最后一个观测点（归一化后坐标）\n",
    "    - lens_out: [N] 每个样本需要预测多少帧 (= num_frames_output)\n",
    "    - keys: [(game_id, play_id, nfl_id), ...]\n",
    "    - play_dirs: 每个样本的原始 play_direction（right/left）\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    last_pos_list = []\n",
    "    len_out_list = []\n",
    "    key_list = []\n",
    "    play_dirs = []\n",
    "\n",
    "    grp = input_df_norm.groupby([\"game_id\", \"play_id\", \"nfl_id\"])\n",
    "    for (g, p, n), df in grp:\n",
    "        df = df.sort_values(\"frame_id\")\n",
    "\n",
    "        feats = df[feature_cols].to_numpy(dtype=np.float32)   # [L_in, F]\n",
    "        L_in = feats.shape[0]\n",
    "        F = feats.shape[1]\n",
    "\n",
    "        # 左侧用 0 填充，保证长度 = T_in\n",
    "        x_seq = np.zeros((T_in, F), dtype=np.float32)\n",
    "        if L_in >= T_in:\n",
    "            x_seq[:] = feats[-T_in:]\n",
    "        else:\n",
    "            x_seq[-L_in:, :] = feats\n",
    "\n",
    "        X_list.append(x_seq)\n",
    "        last_pos_list.append(feats[-1, :2])  # 最后一个观测点 (x,y)\n",
    "        len_out_list.append(int(df[\"num_frames_output\"].iloc[0]))\n",
    "        key_list.append((g, p, n))\n",
    "        play_dirs.append(df[\"play_direction\"].iloc[0])\n",
    "\n",
    "    X_all = np.stack(X_list)                   # [N, T_in, F]\n",
    "    last_pos = np.stack(last_pos_list)         # [N, 2]\n",
    "    lens_out = np.asarray(len_out_list, int)   # [N]\n",
    "\n",
    "    return X_all, last_pos, lens_out, key_list, play_dirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78767872",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:32:09.847690Z",
     "iopub.status.busy": "2025-11-22T08:32:09.847484Z",
     "iopub.status.idle": "2025-11-22T08:32:09.854190Z",
     "shell.execute_reply": "2025-11-22T08:32:09.853423Z"
    },
    "papermill": {
     "duration": 0.014902,
     "end_time": "2025-11-22T08:32:09.855363",
     "exception": false,
     "start_time": "2025-11-22T08:32:09.840461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import polars as pl\n",
    "\n",
    "# 1. 方向特征（跟训练时一样）\n",
    "def add_direction_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    rad_dir = np.deg2rad(df[\"dir\"].astype(float))\n",
    "    rad_o   = np.deg2rad(df[\"o\"].astype(float))\n",
    "    df[\"dir_sin\"] = np.sin(rad_dir)\n",
    "    df[\"dir_cos\"] = np.cos(rad_dir)\n",
    "    df[\"o_sin\"]   = np.sin(rad_o)\n",
    "    df[\"o_cos\"]   = np.cos(rad_o)\n",
    "    return df\n",
    "\n",
    "# 2. 左右归一化（跟训练时的 mirror_xy / normalize_direction 一致）\n",
    "def normalize_direction(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    is_left = df[\"play_direction\"] == \"left\"\n",
    "\n",
    "    df.loc[is_left, \"x\"] = 120.0 - df.loc[is_left, \"x\"]\n",
    "    df.loc[is_left, \"y\"] =  53.3 - df.loc[is_left, \"y\"]\n",
    "\n",
    "    df.loc[is_left, \"dir\"] = (180.0 - df.loc[is_left, \"dir\"]) % 360\n",
    "    df.loc[is_left, \"o\"]   = (180.0 - df.loc[is_left, \"o\"]) % 360\n",
    "\n",
    "    # 注意：这里我们不改 play_direction，让它保持原始值，\n",
    "    # 方便后面还原坐标时根据 \"left\"/\"right\" 判断\n",
    "    return df\n",
    "\n",
    "# 3. 把「统一向右」的预测坐标还原回原始方向\n",
    "def denormalize_xy(xy: np.ndarray, play_direction: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    xy: [T, 2]  在统一向右坐标系下的预测\n",
    "    play_direction: 'left' 或 'right'（原始的）\n",
    "    \"\"\"\n",
    "    if play_direction == \"left\":\n",
    "        xy = xy.copy()\n",
    "        xy[:, 0] = 120.0 - xy[:, 0]\n",
    "        xy[:, 1] =  53.3 - xy[:, 1]\n",
    "    return xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ddf1934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:32:09.868679Z",
     "iopub.status.busy": "2025-11-22T08:32:09.868044Z",
     "iopub.status.idle": "2025-11-22T08:32:09.880708Z",
     "shell.execute_reply": "2025-11-22T08:32:09.880212Z"
    },
    "papermill": {
     "duration": 0.020253,
     "end_time": "2025-11-22T08:32:09.881675",
     "exception": false,
     "start_time": "2025-11-22T08:32:09.861422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "BEST_MODEL_PATH = \"/kaggle/working/model_autoreg_best.pt\"\n",
    "\n",
    "def load_trained_model(device):\n",
    "    # 和训练时完全一样的超参数\n",
    "    T_in  = 32\n",
    "    T_out = 21\n",
    "    feature_cols = [\"x\", \"y\", \"s\", \"a\", \"dir\", \"o\", \"ball_land_x\", \"ball_land_y\"]\n",
    "    input_dim = len(feature_cols)\n",
    "    d_model = 128\n",
    "    nhead = 8\n",
    "    num_layers = 3   # ★ 必须和训练时一致！\n",
    "\n",
    "    model = AutoRegressiveTransformer(\n",
    "        input_dim=input_dim,\n",
    "        d_model=d_model,\n",
    "        nhead=nhead,\n",
    "        num_layers=num_layers,\n",
    "        T_in=T_in,\n",
    "        T_out=T_out,\n",
    "    ).to(device)\n",
    "\n",
    "    state = torch.load(BEST_MODEL_PATH, map_location=device)\n",
    "    # 如果你保存的是 {\"model\": ..., \"rmse\": ...}\n",
    "    state_dict = state[\"model\"] if \"model\" in state else state\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# 这些超参数要跟训练时一致\n",
    "T_in  = 32\n",
    "T_out = 21\n",
    "feature_cols = [\"x\", \"y\", \"s\", \"a\", \"dir\", \"o\", \"ball_land_x\", \"ball_land_y\"]\n",
    "\n",
    "\n",
    "def predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Kaggle 评测时会调用这个函数。\n",
    "    参数:\n",
    "      test:       pl.DataFrame, 只包含 game_id, play_id, nfl_id, frame_id\n",
    "      test_input: pl.DataFrame, 传球前的 tracking (结构类似 train 的 input_2023_w01~18)\n",
    "\n",
    "    返回:\n",
    "      pl.DataFrame, 必须跟 test 一样行数，包含列 ['game_id','play_id','nfl_id','frame_id','x','y']\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = load_trained_model(device)\n",
    "    model.eval()\n",
    "\n",
    "    # 转成 pandas 方便处理\n",
    "    test_df = test.to_pandas()\n",
    "    inp_raw = test_input.to_pandas()\n",
    "\n",
    "    # 记录每个 play 的原始方向，用来最后还原坐标\n",
    "    play_dir_map = (\n",
    "        inp_raw[[\"game_id\", \"play_id\", \"play_direction\"]]\n",
    "        .drop_duplicates()\n",
    "        .set_index([\"game_id\", \"play_id\"])[\"play_direction\"]\n",
    "    )\n",
    "\n",
    "    # 只保留需要预测的那些球员的历史\n",
    "    key_cols = [\"game_id\", \"play_id\", \"nfl_id\"]\n",
    "    inp = inp_raw.merge(\n",
    "        test_df[key_cols].drop_duplicates(),\n",
    "        on=key_cols,\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    # 预处理（和训练完全一样）\n",
    "    inp = add_direction_features(inp)\n",
    "    inp = normalize_direction(inp)\n",
    "\n",
    "    preds_x = np.zeros(len(test_df), dtype=np.float32)\n",
    "    preds_y = np.zeros(len(test_df), dtype=np.float32)\n",
    "\n",
    "    # 按 (game_id, play_id, nfl_id) 分组做预测\n",
    "    for (g, p, nid), grp in test_df.groupby([\"game_id\", \"play_id\", \"nfl_id\"]):\n",
    "        frames = grp[\"frame_id\"].values  # 1-based\n",
    "\n",
    "        hist = inp[(inp.game_id == g) & (inp.play_id == p) & (inp.nfl_id == nid)].copy()\n",
    "        if hist.empty:\n",
    "            # 极端情况：没找到历史，就用 0 填（基本不会发生）\n",
    "            px = np.zeros_like(frames, dtype=np.float32)\n",
    "            py = np.zeros_like(frames, dtype=np.float32)\n",
    "        else:\n",
    "            hist = hist.sort_values(\"frame_id\")\n",
    "            feats = hist[feature_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "            # 取最后 T_in 帧，不够的话前面补 0\n",
    "            if len(feats) >= T_in:\n",
    "                seq_in = feats[-T_in:]\n",
    "            else:\n",
    "                pad = np.zeros((T_in - len(feats), feats.shape[1]), dtype=np.float32)\n",
    "                seq_in = np.concatenate([pad, feats], axis=0)\n",
    "\n",
    "            last_pos = seq_in[-1, :2].copy()  # [x, y] 最后一帧观测位置\n",
    "\n",
    "            xb = torch.from_numpy(seq_in).unsqueeze(0).to(device)  # [1, T_in, F]\n",
    "            with torch.no_grad():\n",
    "                # forward 默认 teacher_forcing_ratio=0，自回归预测相对位移\n",
    "                rel = model(xb)[0].cpu().numpy()  # [T_out, 2]\n",
    "\n",
    "            abs_xy = rel + last_pos[None, :]  # [T_out, 2] 统一向右坐标系\n",
    "\n",
    "            # 还原回原始 play 方向\n",
    "            play_dir = play_dir_map.get((g, p), \"right\")\n",
    "            abs_xy = denormalize_xy(abs_xy, play_dir)\n",
    "\n",
    "            # 把每个 frame_id 对应到预测序列上；>T_out 的用最后一帧顶上\n",
    "            px = np.empty_like(frames, dtype=np.float32)\n",
    "            py = np.empty_like(frames, dtype=np.float32)\n",
    "            for i, fid in enumerate(frames):\n",
    "                idx = int(fid) - 1\n",
    "                if idx < 0:\n",
    "                    idx = 0\n",
    "                if idx >= T_out:\n",
    "                    idx = T_out - 1\n",
    "                px[i] = abs_xy[idx, 0]\n",
    "                py[i] = abs_xy[idx, 1]\n",
    "\n",
    "        preds_x[grp.index.values] = px\n",
    "        preds_y[grp.index.values] = py\n",
    "\n",
    "    out_df = test_df.copy()\n",
    "    out_df[\"x\"] = preds_x\n",
    "    out_df[\"y\"] = preds_y\n",
    "\n",
    "    # 返回 pl.DataFrame，列顺序无所谓，但通常保持一致\n",
    "    return pl.from_pandas(out_df[[\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\", \"x\", \"y\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef1f6390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:32:09.894221Z",
     "iopub.status.busy": "2025-11-22T08:32:09.894019Z",
     "iopub.status.idle": "2025-11-22T08:32:40.975283Z",
     "shell.execute_reply": "2025-11-22T08:32:40.974293Z"
    },
    "papermill": {
     "duration": 31.097533,
     "end_time": "2025-11-22T08:32:40.985082",
     "exception": false,
     "start_time": "2025-11-22T08:32:09.887549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5837, 6)\n",
      "shape: (5, 6)\n",
      "┌────────────┬─────────┬────────┬──────────┬───────────┬───────────┐\n",
      "│ game_id    ┆ play_id ┆ nfl_id ┆ frame_id ┆ x         ┆ y         │\n",
      "│ ---        ┆ ---     ┆ ---    ┆ ---      ┆ ---       ┆ ---       │\n",
      "│ i64        ┆ i64     ┆ i64    ┆ i64      ┆ f32       ┆ f32       │\n",
      "╞════════════╪═════════╪════════╪══════════╪═══════════╪═══════════╡\n",
      "│ 2024120805 ┆ 74      ┆ 54586  ┆ 1        ┆ 88.371056 ┆ 34.209892 │\n",
      "│ 2024120805 ┆ 74      ┆ 54586  ┆ 2        ┆ 88.250854 ┆ 34.326374 │\n",
      "│ 2024120805 ┆ 74      ┆ 54586  ┆ 3        ┆ 88.182755 ┆ 34.439686 │\n",
      "│ 2024120805 ┆ 74      ┆ 54586  ┆ 4        ┆ 88.086403 ┆ 34.676453 │\n",
      "│ 2024120805 ┆ 74      ┆ 54586  ┆ 5        ┆ 88.001495 ┆ 34.81958  │\n",
      "└────────────┴─────────┴────────┴──────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "test_pl = pl.read_csv(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv\")\n",
    "test_input_pl = pl.read_csv(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv\")\n",
    "\n",
    "pred_pl = predict(test_pl, test_input_pl)\n",
    "\n",
    "print(pred_pl.shape)          # 应该是 (len(test_pl), 6) 或至少 (len(test_pl), 2)\n",
    "print(pred_pl.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa817efb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T08:32:41.002703Z",
     "iopub.status.busy": "2025-11-22T08:32:41.002349Z",
     "iopub.status.idle": "2025-11-22T08:32:41.076043Z",
     "shell.execute_reply": "2025-11-22T08:32:41.075034Z"
    },
    "papermill": {
     "duration": 0.085402,
     "end_time": "2025-11-22T08:32:41.077313",
     "exception": false,
     "start_time": "2025-11-22T08:32:40.991911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /kaggle/working/submission.parquet\n",
      "(5837, 6)\n",
      "shape: (5, 6)\n",
      "┌────────────┬─────────┬────────┬──────────┬───────────┬───────────┐\n",
      "│ game_id    ┆ play_id ┆ nfl_id ┆ frame_id ┆ x         ┆ y         │\n",
      "│ ---        ┆ ---     ┆ ---    ┆ ---      ┆ ---       ┆ ---       │\n",
      "│ i64        ┆ i64     ┆ i64    ┆ i64      ┆ f32       ┆ f32       │\n",
      "╞════════════╪═════════╪════════╪══════════╪═══════════╪═══════════╡\n",
      "│ 2024120805 ┆ 74      ┆ 54586  ┆ 1        ┆ 88.371056 ┆ 34.209892 │\n",
      "│ 2024120805 ┆ 74      ┆ 54586  ┆ 2        ┆ 88.250854 ┆ 34.326374 │\n",
      "│ 2024120805 ┆ 74      ┆ 54586  ┆ 3        ┆ 88.182755 ┆ 34.439686 │\n",
      "│ 2024120805 ┆ 74      ┆ 54586  ┆ 4        ┆ 88.086403 ┆ 34.676453 │\n",
      "│ 2024120805 ┆ 74      ┆ 54586  ┆ 5        ┆ 88.001495 ┆ 34.81958  │\n",
      "└────────────┴─────────┴────────┴──────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# 确保列顺序跟 test.csv 一样\n",
    "pred_pl = pred_pl.select([\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\", \"x\", \"y\"])\n",
    "\n",
    "# Kaggle 要求的名字和格式：submission.parquet\n",
    "out_path = \"/kaggle/working/submission.parquet\"\n",
    "pred_pl.write_parquet(out_path)\n",
    "print(\"Saved to:\", out_path)\n",
    "print(pred_pl.shape)\n",
    "print(pred_pl.head())\n",
    "\n",
    "\n",
    "# test_pl = pl.read_csv(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv\")\n",
    "\n",
    "# print(\"test rows:\", test_pl.shape[0])\n",
    "# print(\"pred rows:\", pred_pl.shape[0])\n",
    "\n",
    "# print(\"test columns:\", test_pl.columns)\n",
    "# print(\"pred columns:\", pred_pl.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14210809,
     "sourceId": 114239,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 786.364791,
   "end_time": "2025-11-22T08:32:43.724512",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-22T08:19:37.359721",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
